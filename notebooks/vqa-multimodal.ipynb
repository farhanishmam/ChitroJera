{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8602931,"sourceType":"datasetVersion","datasetId":5113474}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preamble: Install and Import Packages","metadata":{}},{"cell_type":"code","source":"!pip install transformers==4.40.1 git+https://github.com/csebuetnlp/normalizer multilingual-clip open_clip_torch -q","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:15:17.902549Z","iopub.execute_input":"2024-06-05T18:15:17.902830Z","iopub.status.idle":"2024-06-05T18:15:50.453548Z","shell.execute_reply.started":"2024-06-05T18:15:17.902805Z","shell.execute_reply":"2024-06-05T18:15:50.452646Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom torchvision.transforms import Resize\nfrom torchvision.io import read_image, ImageReadMode\nfrom multilingual_clip import Config_MCLIP\nimport open_clip\nimport json\nimport pandas as pd\nimport random\nfrom pathlib import Path\nimport cv2\nimport numpy as np\nimport transformers as hf\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom PIL import Image\nimport os\nimport gc\nimport time\nimport math\nfrom normalizer import normalize","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:17:37.437818Z","iopub.execute_input":"2024-06-05T18:17:37.438694Z","iopub.status.idle":"2024-06-05T18:17:46.292279Z","shell.execute_reply.started":"2024-06-05T18:17:37.438655Z","shell.execute_reply":"2024-06-05T18:17:46.291534Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"torch.autograd.set_detect_anomaly(True)\nhf.__version__","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:17:46.293630Z","iopub.execute_input":"2024-06-05T18:17:46.294046Z","iopub.status.idle":"2024-06-05T18:17:46.300653Z","shell.execute_reply.started":"2024-06-05T18:17:46.294023Z","shell.execute_reply":"2024-06-05T18:17:46.299816Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'4.40.1'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Initialise the Configuration and Random Seeds","metadata":{}},{"cell_type":"code","source":"_text_model_config = {}\n\n_image_model_config = {\n    \"attention_probs_dropout_prob\": 0.0,\n    \"encoder_stride\": 16,\n    \"hidden_act\": \"gelu\",\n    \"hidden_dropout_prob\": 0.0,\n    \"hidden_size\": 768,\n    \"image_size\": 224,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"layer_norm_eps\": 1e-12,\n    \"num_attention_heads\": 12,\n    \"num_channels\": 3,\n    \"num_hidden_layers\": 0,\n    \"patch_size\": 16,\n    \"qkv_bias\": True,\n}\n\n# Dual encoder/Concat\ntokeniser_model_id = 'xlm-roberta-base'\ntext_model_id = 'xlm-roberta-base'\nimage_model_id = 'google/vit-base-patch16-224-in21k'\n\n# CLIP\n# multimodal_model_id = 'openai/clip-vit-base-patch32'\n\n# M-CLIP\n# tokeniser_model_id = 'M-CLIP/XLM-Roberta-Large-Vit-B-16Plus'\n# text_model_id = 'M-CLIP/XLM-Roberta-Large-Vit-B-16Plus'\n# image_model_id = 'ViT-B-16-plus-240'\nimage_training_id = 'laion400m_e32'\n\n# ViLT\nmultimodal_model_id = 'dandelin/vilt-b32-mlm'\n\n\nclass CFG:\n    use_multimodal = True\n    use_dualencoder = False\n    save_models = True\n    is_mclip = False\n    init_weights = False\n    tokeniser_model_id = tokeniser_model_id\n    text_model_id = text_model_id\n    image_model_id = image_model_id\n    multimodal_model_id = multimodal_model_id\n    image_training_id = image_training_id\n    text_model_config = hf.AutoConfig.from_pretrained(text_model_id) if not 'M-CLIP' in text_model_id else None\n    image_model_config = hf.AutoConfig.from_pretrained(image_model_id) if not 'M-CLIP' in text_model_id else None\n    multimodal_model_config = hf.AutoConfig.from_pretrained(multimodal_model_id, text_config=_text_model_config, vision_config=_image_model_config)\n    images_base_path = Path('/kaggle/input/vqa-bangla/Bangla_VQA/Bangla_VQA/images')\n    images_base_path_test = Path('/kaggle/input/vqa-bangla/Bangla_VQA/Bangla_VQA/images')\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    lang = 'en'\n    debug = True\n    print_freq = 50\n    apex = True # for faster training\n    epochs = 10\n    learning_rate = 2e-4  # for adam optimizer\n    eps = 1e-6\n    betas = (0.9, 0.999)  # for adam optimizer\n    batch_size = 128  # 128 if ViLT/CLIP, 32 if BLIP, 4 if M-CLIP\n    max_len = 512\n    weight_decay = 0.01  # for adam optimizer regulaization parameter\n    gradient_accumulation_steps = 1\n    max_grad_norm = 1000\n    seed = 42\n    train = True\n    num_classes = 0\n    mlp_hidden_size = 256\n    mlp_hidden_layers = 0\n    mlp_dropout = 0.1\n    mlp_grad_clip = 1.0\n    mlp_init_range = 0.2\n    mlp_attn_dim = 256","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:00.636486Z","iopub.execute_input":"2024-06-05T18:18:00.637361Z","iopub.status.idle":"2024-06-05T18:18:01.091810Z","shell.execute_reply.started":"2024-06-05T18:18:00.637318Z","shell.execute_reply":"2024-06-05T18:18:01.091101Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3d78d08bdb64f46bf95c1b70c6b96ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e71a93060ba464aab4a30973b92f281"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/653 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"403bd644a92f4b86b961ca4263132ea5"}},"metadata":{}}]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:01.099308Z","iopub.execute_input":"2024-06-05T18:18:01.099607Z","iopub.status.idle":"2024-06-05T18:18:01.107415Z","shell.execute_reply.started":"2024-06-05T18:18:01.099576Z","shell.execute_reply":"2024-06-05T18:18:01.106613Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class MultilingualCLIP(hf.PreTrainedModel):\n    config_class = Config_MCLIP.MCLIPConfig\n\n    def __init__(self, config, *args, **kwargs):\n        super().__init__(config, *args, **kwargs)\n        self.transformer = hf.AutoModel.from_pretrained(config.modelBase, cache_dir=kwargs.get(\"cache_dir\"))\n        self.LinearTransformation = torch.nn.Linear(in_features=config.transformerDimensions,\n                                                    out_features=config.numDims)\n\n    def forward(self, tokens, mask):\n        embs = self.transformer(tokens, attention_mask=mask)[0]\n        embs = (embs * mask.unsqueeze(2)).sum(dim=1) / mask.sum(dim=1)[:, None]\n        return self.LinearTransformation(embs)\n\n    @classmethod\n    def _load_state_dict_into_model(cls, model, state_dict, pretrained_model_name_or_path, _fast_init=True):\n        model.load_state_dict(state_dict)\n        return model, [], [], []","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:03.055557Z","iopub.execute_input":"2024-06-05T18:18:03.056185Z","iopub.status.idle":"2024-06-05T18:18:03.539717Z","shell.execute_reply.started":"2024-06-05T18:18:03.056155Z","shell.execute_reply":"2024-06-05T18:18:03.538898Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess the Dataset","metadata":{}},{"cell_type":"code","source":"def normalise_bn(text_bn):\n    return normalize(\n        text_bn,\n        unicode_norm=\"NFKC\",\n        punct_replacement=None,\n        url_replacement=None,\n        emoji_replacement=None,\n        apply_unicode_norm_last=True\n    )","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:04.645807Z","iopub.execute_input":"2024-06-05T18:18:04.646404Z","iopub.status.idle":"2024-06-05T18:18:04.651486Z","shell.execute_reply.started":"2024-06-05T18:18:04.646374Z","shell.execute_reply":"2024-06-05T18:18:04.650452Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/vqa-bangla/updated_train.csv\")\nval_df = pd.read_csv(\"/kaggle/input/vqa-bangla/updated_valid.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/vqa-bangla/updated_test.csv\")\n\ndf = pd.concat([train_df, val_df, test_df], ignore_index=True)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:05.742557Z","iopub.execute_input":"2024-06-05T18:18:05.742906Z","iopub.status.idle":"2024-06-05T18:18:06.017725Z","shell.execute_reply.started":"2024-06-05T18:18:05.742876Z","shell.execute_reply":"2024-06-05T18:18:06.016805Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"         image_name                                           Captions  \\\n0   bnature_663.jpg  খালের পানিতে তিনটি গাছের প্রতিচ্ছবি সাথে গৌধোল...   \n1  chitron_5113.png  অনেকগুলো মানুষ বসে আছে। মঞ্চের উপর কয়েকজন মানু...   \n2   bnature_876.jpg  দুজন ছেলে ও দুজন মেয়ে রাস্তা দিয়ে পাশাপাশি হ...   \n3  bnature_1007.jpg  রাস্তা দিয়ে কয়েকজন ছাত্র ছাত্রী যাচ্ছে, যাদে...   \n4  chitron_7446.png  '১ ইট তালগাছ ১ টি খেজুর গাছ এবং রাস্তা দিয়ে ছা...   \n\n                                       Question  Answer Category  \\\n0    ছবিতে কতগুলো গাছের প্রতিচ্ছবি দেখা যাচ্ছে?   তিনটি  numeric   \n1      ছবিতে কতজন মানুষ মঞ্চের উপর দাঁড়িয়ে আছে?  পাঁচজন  numeric   \n2         ছবিতে কতজন ছেলে ও মেয়ে একসাথে হাটছে?   চারজন  numeric   \n3  ছবিতে কতজন ছাত্র ছাত্রী রাস্তা দিয়ে হাঁটছে?    ৪ জন  numeric   \n4                 ছবিতে কতগুলো গাছ দেখা যাচ্ছে?    ২ টি  numeric   \n\n                                         Question_en Answer_en  \\\n0       How many trees are reflected in the picture?     three   \n1                  How many people are on the stage?      five   \n2  How many boys and girls are walking together i...      four   \n3  How many students are walking on the street in...      four   \n4           How many trees are shown in the picture?       Two   \n\n                                         Captions_en Answer_fixed  \n0  Goudholi's beauty with three trees reflected i...          তিন  \n1  A lot of people were sitting, a few people wer...         পাঁচ  \n2  Two boys and two girls walking side by side on...          চার  \n3  Several students walking on the street, carryi...          চার  \n4  1 brick palm tree 1 date tree and 4 school stu...          দুই  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>Captions</th>\n      <th>Question</th>\n      <th>Answer</th>\n      <th>Category</th>\n      <th>Question_en</th>\n      <th>Answer_en</th>\n      <th>Captions_en</th>\n      <th>Answer_fixed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bnature_663.jpg</td>\n      <td>খালের পানিতে তিনটি গাছের প্রতিচ্ছবি সাথে গৌধোল...</td>\n      <td>ছবিতে কতগুলো গাছের প্রতিচ্ছবি দেখা যাচ্ছে?</td>\n      <td>তিনটি</td>\n      <td>numeric</td>\n      <td>How many trees are reflected in the picture?</td>\n      <td>three</td>\n      <td>Goudholi's beauty with three trees reflected i...</td>\n      <td>তিন</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>chitron_5113.png</td>\n      <td>অনেকগুলো মানুষ বসে আছে। মঞ্চের উপর কয়েকজন মানু...</td>\n      <td>ছবিতে কতজন মানুষ মঞ্চের উপর দাঁড়িয়ে আছে?</td>\n      <td>পাঁচজন</td>\n      <td>numeric</td>\n      <td>How many people are on the stage?</td>\n      <td>five</td>\n      <td>A lot of people were sitting, a few people wer...</td>\n      <td>পাঁচ</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bnature_876.jpg</td>\n      <td>দুজন ছেলে ও দুজন মেয়ে রাস্তা দিয়ে পাশাপাশি হ...</td>\n      <td>ছবিতে কতজন ছেলে ও মেয়ে একসাথে হাটছে?</td>\n      <td>চারজন</td>\n      <td>numeric</td>\n      <td>How many boys and girls are walking together i...</td>\n      <td>four</td>\n      <td>Two boys and two girls walking side by side on...</td>\n      <td>চার</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bnature_1007.jpg</td>\n      <td>রাস্তা দিয়ে কয়েকজন ছাত্র ছাত্রী যাচ্ছে, যাদে...</td>\n      <td>ছবিতে কতজন ছাত্র ছাত্রী রাস্তা দিয়ে হাঁটছে?</td>\n      <td>৪ জন</td>\n      <td>numeric</td>\n      <td>How many students are walking on the street in...</td>\n      <td>four</td>\n      <td>Several students walking on the street, carryi...</td>\n      <td>চার</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>chitron_7446.png</td>\n      <td>'১ ইট তালগাছ ১ টি খেজুর গাছ এবং রাস্তা দিয়ে ছা...</td>\n      <td>ছবিতে কতগুলো গাছ দেখা যাচ্ছে?</td>\n      <td>২ টি</td>\n      <td>numeric</td>\n      <td>How many trees are shown in the picture?</td>\n      <td>Two</td>\n      <td>1 brick palm tree 1 date tree and 4 school stu...</td>\n      <td>দুই</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"all_labels = list(set(df['Answer' if CFG.lang == 'bn' else 'Answer_en'].unique().astype(str)))\nall_labels.sort()\nlabel_map = dict()\nCFG.num_classes = len(all_labels)\nfor idx, label in enumerate(all_labels):\n    label_map[normalise_bn(str(label)) if CFG.lang == 'bn' else str(label)] = idx","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:06.573314Z","iopub.execute_input":"2024-06-05T18:18:06.573657Z","iopub.status.idle":"2024-06-05T18:18:06.593162Z","shell.execute_reply.started":"2024-06-05T18:18:06.573630Z","shell.execute_reply":"2024-06-05T18:18:06.592409Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Initialise the Processors/Tokenisers/Models","metadata":{}},{"cell_type":"code","source":"if CFG.is_mclip:\n    tokenizer = hf.AutoTokenizer.from_pretrained(CFG.tokeniser_model_id)\n    text_model = MultilingualCLIP.from_pretrained(CFG.text_model_id).to(CFG.device)\n    image_model, _, image_processor = open_clip.create_model_and_transforms(CFG.image_model_id, pretrained=CFG.image_training_id)\n    image_model = image_model.to(CFG.device)\nelif CFG.use_multimodal:\n    mm_processor = hf.AutoProcessor.from_pretrained(CFG.multimodal_model_id)\n    mm_model = hf.AutoModel.from_pretrained(CFG.multimodal_model_id).to(CFG.device)\nelif CFG.use_dualencoder:\n    tokenizer = hf.AutoTokenizer.from_pretrained(CFG.tokeniser_model_id, padding=True, truncation=True)\n    processor = hf.AutoImageProcessor.from_pretrained(CFG.image_model_id)\n    de_processor = hf.VisionTextDualEncoderProcessor(image_processor=processor, tokenizer=tokenizer)\n    text_model = hf.AutoModel.from_pretrained(CFG.text_model_id).to(CFG.device)\n    image_model = hf.AutoModel.from_pretrained(CFG.image_model_id).to(CFG.device)\n    de_model = hf.VisionTextDualEncoderModel(vision_model=image_model, text_model=text_model)\nelse:\n    tokenizer = hf.AutoTokenizer.from_pretrained(CFG.tokeniser_model_id)\n    text_model = hf.AutoModel.from_pretrained(CFG.text_model_id).to(CFG.device)\n    # Adding a config to the image_model gets rid of lots of pretrained weights\n    image_model = hf.AutoModel.from_pretrained(CFG.image_model_id).to(CFG.device)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:15.130362Z","iopub.execute_input":"2024-06-05T18:18:15.130719Z","iopub.status.idle":"2024-06-05T18:18:26.600269Z","shell.execute_reply.started":"2024-06-05T18:18:15.130690Z","shell.execute_reply":"2024-06-05T18:18:26.599444Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5751b7d05c4d4c4e849a78c3d036e7f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e57c0b73a8646dd8b49dd4875054ce6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc7ec96260af4ee895504bb1eb5af9f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"265d281448d446dd9b410b722f9d170d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79ad7ab38b364d05aaaa5d476b711c26"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Custom Dataset Definition","metadata":{}},{"cell_type":"code","source":"class VQADataset(Dataset):\n    def __init__(self, features, img_dir, img_transform=None, caption_transform=None, target_transform=None):\n        self.features = features\n        self.img_dir = img_dir\n        self.img_transform = img_transform\n        self.caption_transform = caption_transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        img_path = str(self.img_dir.joinpath(self.features['image_name'].iloc[idx]))\n        if CFG.is_mclip:\n            image = Image.open(img_path)\n        else:\n            image = read_image(img_path, mode=ImageReadMode.RGB).to(device=CFG.device)\n        caption = normalise_bn(self.features['Question' if CFG.lang == 'bn' else 'Question_en'].iloc[idx])\n        identity = self.features['image_name'].iloc[idx]\n        label = torch.tensor(label_map[normalise_bn(str(self.features['Answer'].iloc[idx])) if CFG.lang == 'bn' else str(self.features['Answer_en'].iloc[idx])], dtype=torch.long)\n        \n        if self.img_transform:\n            image = self.img_transform(image)\n        if self.caption_transform:\n            caption = self.caption_transform(caption)\n        if self.target_transform:\n            label = self.target_transform(label)\n            \n        if CFG.is_mclip:\n            processed = tokenizer(caption, padding=True, return_tensors='pt')\n            seq = processed['input_ids']\n            mask = processed['attention_mask']\n            image = image_processor(image)\n        elif CFG.use_multimodal:\n            processed = mm_processor(text=caption, images=image, return_tensors=\"pt\", padding=True, truncation=True)\n            seq = processed['input_ids']\n            mask = processed['attention_mask']\n            image = processed['pixel_values']\n        elif CFG.use_dualencoder:\n            processed = de_processor(text=caption, images=image, return_tensors=\"pt\")\n            seq = processed['input_ids']\n            mask = processed['attention_mask']\n            image = processed['pixel_values']\n        else:\n            processed = tokenizer.encode_plus(\n                caption,\n                padding='longest',\n                truncation=True,\n                return_tensors='pt'\n            )\n            seq = processed['input_ids']\n            mask = processed['attention_mask']\n        \n        return identity, image, seq, mask, label","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:26.601817Z","iopub.execute_input":"2024-06-05T18:18:26.602107Z","iopub.status.idle":"2024-06-05T18:18:26.616580Z","shell.execute_reply.started":"2024-06-05T18:18:26.602082Z","shell.execute_reply":"2024-06-05T18:18:26.615634Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class Collator(object):\n    def __init__(self, test=False):\n        self.test = test\n    def __call__(self, batch):\n        ids, images, seqs, masks, labels = zip(*batch)\n\n        seqs = [seq.squeeze(dim=0) for seq in seqs]\n        masks = [mask.squeeze(dim=0) for mask in masks]\n        images = [image.squeeze(dim=0) for image in images]\n        labels = torch.stack(labels)\n\n        seqs = nn.utils.rnn.pad_sequence(seqs, batch_first=True)\n        masks = nn.utils.rnn.pad_sequence(masks, batch_first=True)\n\n        images = torch.stack(images)\n        \n        return ids, images, seqs, masks, labels","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:26.617900Z","iopub.execute_input":"2024-06-05T18:18:26.618674Z","iopub.status.idle":"2024-06-05T18:18:26.630346Z","shell.execute_reply.started":"2024-06-05T18:18:26.618640Z","shell.execute_reply":"2024-06-05T18:18:26.629430Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"resizer = Resize((224, 224), antialias=True)\n\ndef resize_images(img_tensor):\n    return resizer(img_tensor)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:26.632782Z","iopub.execute_input":"2024-06-05T18:18:26.633156Z","iopub.status.idle":"2024-06-05T18:18:26.640978Z","shell.execute_reply.started":"2024-06-05T18:18:26.633121Z","shell.execute_reply":"2024-06-05T18:18:26.640231Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Initialisation","metadata":{}},{"cell_type":"code","source":"train_dataset = VQADataset(train_df, CFG.images_base_path, img_transform=resize_images)\nval_dataset = VQADataset(val_df, CFG.images_base_path, img_transform=resize_images)\ntest_dataset = VQADataset(test_df, CFG.images_base_path, img_transform=resize_images)\n\nprint(len(train_dataset))\nprint(len(val_dataset))\nprint(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:26.642289Z","iopub.execute_input":"2024-06-05T18:18:26.642669Z","iopub.status.idle":"2024-06-05T18:18:26.649312Z","shell.execute_reply.started":"2024-06-05T18:18:26.642638Z","shell.execute_reply":"2024-06-05T18:18:26.648507Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"12231\n1529\n1532\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"class MultiModalArch(nn.Module):\n    def __init__(self, hidden_size, hidden_layers, dropout, num_classes, use_multimodal=False, use_dualencoder=False, is_mclip=False):\n        super().__init__()\n        \n        self.hidden_size = hidden_size\n        self.hidden_layers = hidden_layers\n        self.use_multimodal = use_multimodal\n        self.use_dualencoder = use_dualencoder\n        self.is_mclip = is_mclip\n        self.is_vilt = 'ViltForMaskedLM' in CFG.multimodal_model_config.architectures\n        \n        if self.is_mclip:\n            self.text_model = text_model\n            self.image_model = image_model\n        elif self.use_multimodal:\n            self.mm_model = mm_model\n        elif self.use_dualencoder:\n            self.de_model = de_model\n        else:\n            self.text_model = text_model\n            self.image_model = image_model\n        \n        if self.is_mclip:\n            self.fc1 = nn.Linear(1280, self.hidden_size)\n        elif self.use_multimodal:\n            if self.is_vilt:\n                out_channels = CFG.multimodal_model_config.hidden_size\n            else:\n                out_channels = 2 * CFG.multimodal_model_config.projection_dim\n            self.fc1 = nn.Linear(out_channels, self.hidden_size)\n        elif self.use_dualencoder:\n            self.fc1 = nn.Linear(2 * 512, self.hidden_size)\n        else:\n            self.fc1 = nn.Linear(CFG.text_model_config.hidden_size + CFG.image_model_config.hidden_size, self.hidden_size)\n        self.hiddens = nn.ModuleList([nn.Linear(self.hidden_size, self.hidden_size) for _ in range(self.hidden_layers)])\n        self.fc2 = nn.Linear(self.hidden_size, num_classes)\n        self.activation = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n        \n        if CFG.init_weights:\n            self._init_weights(self.fc1)\n            for hidden in self.hiddens:\n                self._init_weights(hidden)\n            self._init_weights(self.fc2)\n\n    def forward(self, tokens, mask, image):\n        if self.is_mclip:\n            emb_text = self.text_model.forward(tokens, mask)\n            emb_img = self.image_model.encode_image(image)\n            x = torch.cat([emb_text, emb_img], dim=1)\n        elif self.use_multimodal:\n            mm_output = self.mm_model(input_ids=tokens, attention_mask=mask, pixel_values=image, output_hidden_states=True)\n            cats = [mm_output.pooler_output] if self.is_vilt else [mm_output.text_embeds, mm_output.image_embeds]\n            x = torch.cat(cats, dim=1)\n        elif self.use_dualencoder:\n            de_output = self.de_model(input_ids=tokens, attention_mask=mask, pixel_values=image)\n            x = torch.cat([de_output.text_embeds, de_output.image_embeds], dim=1)\n        else:\n            cls_text = self.text_model(tokens, attention_mask=mask).last_hidden_state[:, 0, :]\n            cls_img = self.image_model(image).last_hidden_state[:, 0, :]\n            x = torch.cat([cls_text, cls_img], dim=1)\n\n        x = self.fc1(x)\n        x = self.activation(x)\n        x = self.dropout(x)\n        for hidden in self.hiddens:\n            x = hidden(x)\n            x = self.activation(x)\n            x = self.dropout(x)\n        x = self.fc2(x)\n        \n        output = x\n        return output.float()\n    \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=CFG.mlp_init_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=CFG.mlp_init_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:26.650534Z","iopub.execute_input":"2024-06-05T18:18:26.650826Z","iopub.status.idle":"2024-06-05T18:18:26.670631Z","shell.execute_reply.started":"2024-06-05T18:18:26.650794Z","shell.execute_reply":"2024-06-05T18:18:26.669886Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Utility Functions","metadata":{}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:26.671608Z","iopub.execute_input":"2024-06-05T18:18:26.671895Z","iopub.status.idle":"2024-06-05T18:18:26.681807Z","shell.execute_reply.started":"2024-06-05T18:18:26.671862Z","shell.execute_reply":"2024-06-05T18:18:26.681007Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def get_score(y_trues, y_preds):\n    accuracy = accuracy_score(y_trues, y_preds)\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:26.682769Z","iopub.execute_input":"2024-06-05T18:18:26.683022Z","iopub.status.idle":"2024-06-05T18:18:26.692436Z","shell.execute_reply.started":"2024-06-05T18:18:26.683000Z","shell.execute_reply":"2024-06-05T18:18:26.691706Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class NpEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.integer):\n            return int(obj)\n        if isinstance(obj, np.floating):\n            return float(obj)\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        return super(NpEncoder, self).default(obj)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:26.693394Z","iopub.execute_input":"2024-06-05T18:18:26.693640Z","iopub.status.idle":"2024-06-05T18:18:26.701112Z","shell.execute_reply.started":"2024-06-05T18:18:26.693617Z","shell.execute_reply":"2024-06-05T18:18:26.700376Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Logger File\n# ====================================================\n\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n\nOUTPUT_DIR = \"./\"\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:26.703438Z","iopub.execute_input":"2024-06-05T18:18:26.703702Z","iopub.status.idle":"2024-06-05T18:18:26.710947Z","shell.execute_reply.started":"2024-06-05T18:18:26.703680Z","shell.execute_reply":"2024-06-05T18:18:26.710115Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Train/Val Loops","metadata":{}},{"cell_type":"code","source":"def train_loop(model, optimizer, loss_fn, train_dataloader, epoch):\n    model.train()\n    train_losses = AverageMeter()\n    start = end = time.time()\n    \n    for step, (_, image, seq, mask, label) in enumerate(tqdm(train_dataloader)):\n        \n        train_image = image.to(CFG.device)\n        train_seq = seq.to(CFG.device)\n        train_mask = mask.to(CFG.device)\n        train_label = label.to(device=CFG.device)\n        \n        batch_size = train_image.shape[0]\n\n        with torch.cuda.amp.autocast(enabled=CFG.apex):\n            output = model(train_seq, train_mask, train_image)\n            \n        loss = loss_fn(output, train_label)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), CFG.mlp_grad_clip)\n        optimizer.step()\n        \n        train_losses.update(loss.item(), batch_size)\n            \n        end = time.time()\n\n        if step % CFG.print_freq == 0 or step == (len(train_dataloader) - 1):\n            print(f'Epoch: [{epoch + 1}][{step}/{len(train_dataloader)}] '\n                  f'Elapsed {timeSince(start, float(step + 1) / len(train_dataloader)):s} '\n                  f'Loss: {train_losses.val:.4f} ({train_losses.avg:.4f}) ')\n        \n        if step % 100 == 0:\n            torch.cuda.empty_cache()\n            gc.collect()\n\n    return train_losses.avg","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:26.945282Z","iopub.execute_input":"2024-06-05T18:18:26.945662Z","iopub.status.idle":"2024-06-05T18:18:26.955170Z","shell.execute_reply.started":"2024-06-05T18:18:26.945636Z","shell.execute_reply":"2024-06-05T18:18:26.954292Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def validation_loop(model, loss_fn, valid_dataloader, epoch):\n    all_ids = []\n    all_preds = []\n    all_labels = []\n    \n    model.eval()\n    validation_losses = AverageMeter()\n    start = end = time.time()\n    global_step = 0\n    \n    for step, (identity, image, seq, mask, label) in enumerate(tqdm(valid_dataloader)):\n        \n        image = image.to(device=CFG.device)\n        seq = seq.to(device=CFG.device)\n        mask = mask.to(device=CFG.device)\n        label = label.to(device=CFG.device)\n        \n        batch_size = image.shape[0]\n\n        with torch.no_grad():\n            with torch.cuda.amp.autocast(enabled=CFG.apex):\n                output = model(seq, mask, image)\n\n        loss = loss_fn(output, label)\n        \n        validation_losses.update(loss.item(), batch_size)\n        predicted = output.argmax(dim=1)\n\n        all_ids += list(identity)\n        all_labels.append(label)\n        all_preds.append(predicted)\n            \n        end = time.time()\n\n        if step % CFG.print_freq == 0 or step == (len(valid_dataloader) - 1):\n            print(f'Epoch: [{epoch + 1}][{step}/{len(valid_dataloader)}] '\n                  f'Elapsed {timeSince(start, float(step + 1) / len(valid_dataloader)):s} '\n                  f'Loss: {validation_losses.val:.4f} ({validation_losses.avg:.4f})')\n        \n        if step % 100 == 0:\n            torch.cuda.empty_cache()\n            gc.collect()\n            \n    all_preds = torch.cat(all_preds, dim=0)\n    all_labels = torch.cat(all_labels, dim=0)\n    \n    all_preds_np = all_preds.cpu().numpy().astype(int)\n    all_labels_np = all_labels.cpu().numpy().astype(int)\n        \n    return validation_losses.avg, all_ids, all_preds_np, all_labels_np","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:27.474549Z","iopub.execute_input":"2024-06-05T18:18:27.475312Z","iopub.status.idle":"2024-06-05T18:18:27.486290Z","shell.execute_reply.started":"2024-06-05T18:18:27.475284Z","shell.execute_reply":"2024-06-05T18:18:27.485364Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def save_predictions(model_name, ids, labels, preds, split='val'):\n    entries = []\n    for identity, label, pred in zip(ids, labels, preds):\n        entry = {\n            'identity': identity,\n            'label': all_labels[label],\n            'pred': all_labels[pred]\n        }\n        entries.append(entry)\n\n    with open(f'/kaggle/working/{model_name}_{CFG.lang}_{split}_preds.json', 'w') as fp:\n        json.dump(entries, fp, cls=NpEncoder)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:28.002495Z","iopub.execute_input":"2024-06-05T18:18:28.003140Z","iopub.status.idle":"2024-06-05T18:18:28.008748Z","shell.execute_reply.started":"2024-06-05T18:18:28.003112Z","shell.execute_reply":"2024-06-05T18:18:28.007783Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Training and Validation","metadata":{}},{"cell_type":"code","source":"collate = Collator()\ntrain_dataloader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, collate_fn=collate)\nvalid_dataloader = DataLoader(val_dataset, batch_size=CFG.batch_size, shuffle=False, collate_fn=collate)\ntest_dataloader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, collate_fn=collate)\n\nloss_fn = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:30.109664Z","iopub.execute_input":"2024-06-05T18:18:30.110611Z","iopub.status.idle":"2024-06-05T18:18:30.118202Z","shell.execute_reply.started":"2024-06-05T18:18:30.110559Z","shell.execute_reply":"2024-06-05T18:18:30.116874Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model = MultiModalArch(\n    hidden_size=CFG.mlp_hidden_size,\n    hidden_layers=CFG.mlp_hidden_layers,\n    dropout=CFG.mlp_dropout,\n    num_classes=CFG.num_classes,\n    use_multimodal=CFG.use_multimodal,\n    use_dualencoder=CFG.use_dualencoder,\n    is_mclip=CFG.is_mclip\n).to(CFG.device)\nif not CFG.is_mclip:\n    model = nn.DataParallel(model)\n\noptim = AdamW(model.parameters(), lr=CFG.learning_rate, eps=CFG.eps, betas=CFG.betas)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:31.564770Z","iopub.execute_input":"2024-06-05T18:18:31.565126Z","iopub.status.idle":"2024-06-05T18:18:32.516854Z","shell.execute_reply.started":"2024-06-05T18:18:31.565095Z","shell.execute_reply":"2024-06-05T18:18:32.515824Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"best_score = float('-inf')\n\nfor epoch in range(CFG.epochs):\n\n    start_time = time.time()\n\n    # train function \n    avg_train_loss = train_loop(model, optim, loss_fn, train_dataloader, epoch)\n\n    # val function \n    avg_val_loss, all_ids, all_preds_np, all_labels_np = validation_loop(model, loss_fn, valid_dataloader, epoch)\n    \n    score = get_score(all_labels_np, all_preds_np)\n    \n    report = classification_report(all_labels_np, all_preds_np, digits=4)\n\n    elapsed = time.time() - start_time\n\n    LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n\n    if CFG.save_models and score > best_score:\n        model_name = CFG.multimodal_model_id if CFG.use_multimodal else '-'.join([CFG.text_model_id, CFG.image_model_id])\n        model_name = model_name.replace('/', '-') + f'_score_{score:.4f}' + f'_{CFG.lang}'\n        torch.save({'model': model.state_dict()}, f'{model_name}.pth')\n        print(f'Saved model: {model_name}')\n        with open(f'{model_name}_results.txt', 'w', encoding='utf-8') as fp:\n            fp.write(report)\n        best_score = score\n        \n        save_predictions(model_name, all_ids, all_labels_np, all_preds_np)\n        \n        avg_test_loss, all_ids_test, all_preds_np_test, all_labels_np_test = validation_loop(model, loss_fn, test_dataloader, epoch)\n        save_predictions(model_name, all_ids_test, all_labels_np_test, all_preds_np_test, split='test')\n\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:18:32.536623Z","iopub.execute_input":"2024-06-05T18:18:32.537022Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84485f62980e40acbe23dfaaae2e10fd"}},"metadata":{}},{"name":"stdout","text":"Epoch: [1][0/96] Elapsed 0m 8s (remain 12m 59s) Loss: 8.3639 (8.3639) \nEpoch: [1][50/96] Elapsed 3m 45s (remain 3m 18s) Loss: 6.8856 (7.6252) \nEpoch: [1][95/96] Elapsed 6m 56s (remain 0m 0s) Loss: 7.3370 (7.4193) \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f6c57a0bc9c4e71afcf0a0fd229ab0f"}},"metadata":{}},{"name":"stdout","text":"Epoch: [1][0/12] Elapsed 0m 2s (remain 0m 28s) Loss: 4.0357 (4.0357)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1 - avg_train_loss: 7.4193  avg_val_loss: 7.0895  time: 446s\n","output_type":"stream"},{"name":"stdout","text":"Epoch: [1][11/12] Elapsed 0m 29s (remain 0m 0s) Loss: 7.9695 (7.0895)\nSaved model: xlm-roberta-base-google-vit-base-patch16-224-in21k_score_0.0713_en\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce5edb943a154012864cbfa25488d3af"}},"metadata":{}},{"name":"stdout","text":"Epoch: [1][0/12] Elapsed 0m 2s (remain 0m 32s) Loss: 6.7488 (6.7488)\nEpoch: [1][11/12] Elapsed 0m 31s (remain 0m 0s) Loss: 8.0759 (7.6523)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5941e694592d49519ed07938d515a909"}},"metadata":{}},{"name":"stdout","text":"Epoch: [2][0/96] Elapsed 0m 4s (remain 6m 35s) Loss: 7.1166 (7.1166) \n","output_type":"stream"}]},{"cell_type":"code","source":"# del model\n# torch.cuda.empty_cache()\n# gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference From Checkpoint","metadata":{}},{"cell_type":"code","source":"# inf_model_name = 'M-CLIP-XLM-Roberta-Large-Vit-B-16Plus-ViT-B-16-plus-240_score_0.0190'\n# inf_model = MultiModalArch(\n#     hidden_size=CFG.mlp_hidden_size,\n#     hidden_layers=CFG.mlp_hidden_layers,\n#     dropout=CFG.mlp_dropout,\n#     num_classes=CFG.num_classes,\n#     use_multimodal=CFG.use_multimodal,\n#     use_dualencoder=CFG.use_dualencoder,\n#     is_mclip=CFG.is_mclip\n# ).to(CFG.device)\n# if not CFG.is_mclip:\n#     inf_model = nn.DataParallel(inf_model)\n# inf_model.load_state_dict(torch.load('/kaggle/working/' + inf_model_name + f'_{CFG.lang}' + '.pth', map_location=torch.device(CFG.device))['model'])\n# inf_model","metadata":{"execution":{"iopub.status.busy":"2024-06-05T09:32:12.809945Z","iopub.execute_input":"2024-06-05T09:32:12.810326Z","iopub.status.idle":"2024-06-05T09:32:15.075958Z","shell.execute_reply.started":"2024-06-05T09:32:12.810295Z","shell.execute_reply":"2024-06-05T09:32:15.075046Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"MultiModalArch(\n  (text_model): MultilingualCLIP(\n    (transformer): XLMRobertaModel(\n      (embeddings): XLMRobertaEmbeddings(\n        (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n        (token_type_embeddings): Embedding(1, 1024)\n        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): XLMRobertaEncoder(\n        (layer): ModuleList(\n          (0-23): 24 x XLMRobertaLayer(\n            (attention): XLMRobertaAttention(\n              (self): XLMRobertaSelfAttention(\n                (query): Linear(in_features=1024, out_features=1024, bias=True)\n                (key): Linear(in_features=1024, out_features=1024, bias=True)\n                (value): Linear(in_features=1024, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): XLMRobertaSelfOutput(\n                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): XLMRobertaIntermediate(\n              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): XLMRobertaOutput(\n              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (pooler): XLMRobertaPooler(\n        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n        (activation): Tanh()\n      )\n    )\n    (LinearTransformation): Linear(in_features=1024, out_features=640, bias=True)\n  )\n  (image_model): CLIP(\n    (visual): VisionTransformer(\n      (conv1): Conv2d(3, 896, kernel_size=(16, 16), stride=(16, 16), bias=False)\n      (patch_dropout): Identity()\n      (ln_pre): LayerNorm((896,), eps=1e-05, elementwise_affine=True)\n      (transformer): Transformer(\n        (resblocks): ModuleList(\n          (0-11): 12 x ResidualAttentionBlock(\n            (ln_1): LayerNorm((896,), eps=1e-05, elementwise_affine=True)\n            (attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=896, out_features=896, bias=True)\n            )\n            (ls_1): Identity()\n            (ln_2): LayerNorm((896,), eps=1e-05, elementwise_affine=True)\n            (mlp): Sequential(\n              (c_fc): Linear(in_features=896, out_features=3584, bias=True)\n              (gelu): GELU(approximate='none')\n              (c_proj): Linear(in_features=3584, out_features=896, bias=True)\n            )\n            (ls_2): Identity()\n          )\n        )\n      )\n      (ln_post): LayerNorm((896,), eps=1e-05, elementwise_affine=True)\n    )\n    (transformer): Transformer(\n      (resblocks): ModuleList(\n        (0-11): 12 x ResidualAttentionBlock(\n          (ln_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=640, out_features=640, bias=True)\n          )\n          (ls_1): Identity()\n          (ln_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n          (mlp): Sequential(\n            (c_fc): Linear(in_features=640, out_features=2560, bias=True)\n            (gelu): GELU(approximate='none')\n            (c_proj): Linear(in_features=2560, out_features=640, bias=True)\n          )\n          (ls_2): Identity()\n        )\n      )\n    )\n    (token_embedding): Embedding(49408, 640)\n    (ln_final): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n  )\n  (fc1): Linear(in_features=1280, out_features=256, bias=True)\n  (hiddens): ModuleList()\n  (fc2): Linear(in_features=256, out_features=5699, bias=True)\n  (activation): ReLU()\n  (dropout): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# avg_val_loss, all_ids, all_preds_np, all_labels_np = validation_loop(inf_model, loss_fn, valid_dataloader, 0)\n# if CFG.debug:\n#     print(all_labels_np)\n#     print(all_preds_np)\n    \n# score = get_score(all_labels_np, all_preds_np)\n\n# report = classification_report(all_labels_np, all_preds_np, digits=4)\n# print(report)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-05T09:32:22.709721Z","iopub.execute_input":"2024-06-05T09:32:22.710415Z","iopub.status.idle":"2024-06-05T09:33:46.255931Z","shell.execute_reply.started":"2024-06-05T09:32:22.710386Z","shell.execute_reply":"2024-06-05T09:33:46.254937Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/383 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe77a2a919ff4c2e8200cf7d234c01aa"}},"metadata":{}},{"name":"stdout","text":"Epoch: [1][0/383] Elapsed 0m 2s (remain 15m 4s) Loss: 4.7221 (4.7221)\nEpoch: [1][50/383] Elapsed 0m 11s (remain 1m 17s) Loss: 4.5757 (5.1672)\nEpoch: [1][100/383] Elapsed 0m 21s (remain 1m 0s) Loss: 9.3990 (5.9564)\nEpoch: [1][150/383] Elapsed 0m 35s (remain 0m 55s) Loss: 8.6295 (6.8906)\nEpoch: [1][200/383] Elapsed 0m 44s (remain 0m 40s) Loss: 8.5118 (7.4440)\nEpoch: [1][250/383] Elapsed 0m 57s (remain 0m 30s) Loss: 10.6316 (7.7586)\nEpoch: [1][300/383] Elapsed 1m 7s (remain 0m 18s) Loss: 4.1957 (7.9083)\nEpoch: [1][350/383] Elapsed 1m 18s (remain 0m 7s) Loss: 9.2648 (7.7561)\nEpoch: [1][382/383] Elapsed 1m 23s (remain 0m 0s) Loss: 6.7356 (7.8342)\n[2661 5640 2099 ... 1978  867 4205]\n[2211 2211 2211 ... 2211 2211 2211]\n              precision    recall  f1-score   support\n\n           7     0.0000    0.0000    0.0000         1\n          17     0.0000    0.0000    0.0000         1\n          20     0.0000    0.0000    0.0000         1\n          22     0.0000    0.0000    0.0000         1\n          26     0.0000    0.0000    0.0000         1\n          27     0.0000    0.0000    0.0000         1\n          28     0.0000    0.0000    0.0000         1\n          33     0.0000    0.0000    0.0000         1\n          35     0.0000    0.0000    0.0000         1\n          37     0.0000    0.0000    0.0000         1\n          38     0.0000    0.0000    0.0000         1\n          46     0.0000    0.0000    0.0000         1\n          61     0.0000    0.0000    0.0000         1\n          67     0.0000    0.0000    0.0000         1\n          68     0.0000    0.0000    0.0000         1\n          75     0.0000    0.0000    0.0000         1\n          96     0.0000    0.0000    0.0000         1\n          98     0.0000    0.0000    0.0000         1\n         108     0.0000    0.0000    0.0000         1\n         109     0.0000    0.0000    0.0000         1\n         112     0.0000    0.0000    0.0000         2\n         118     0.0000    0.0000    0.0000         1\n         136     0.0000    0.0000    0.0000         1\n         141     0.0000    0.0000    0.0000         2\n         142     0.0000    0.0000    0.0000         2\n         146     0.0000    0.0000    0.0000         1\n         168     0.0000    0.0000    0.0000         1\n         181     0.0000    0.0000    0.0000         1\n         182     0.0000    0.0000    0.0000         2\n         191     0.0000    0.0000    0.0000         1\n         192     0.0000    0.0000    0.0000         1\n         197     0.0000    0.0000    0.0000         1\n         198     0.0000    0.0000    0.0000         1\n         202     0.0000    0.0000    0.0000         2\n         214     0.0000    0.0000    0.0000         1\n         247     0.0000    0.0000    0.0000         1\n         255     0.0000    0.0000    0.0000         1\n         265     0.0000    0.0000    0.0000         1\n         268     0.0000    0.0000    0.0000         1\n         279     0.0000    0.0000    0.0000         1\n         284     0.0000    0.0000    0.0000         1\n         292     0.0000    0.0000    0.0000         1\n         296     0.0000    0.0000    0.0000         1\n         305     0.0000    0.0000    0.0000         1\n         311     0.0000    0.0000    0.0000         1\n         320     0.0000    0.0000    0.0000         1\n         321     0.0000    0.0000    0.0000        18\n         326     0.0000    0.0000    0.0000         1\n         336     0.0000    0.0000    0.0000         1\n         337     0.0000    0.0000    0.0000         3\n         344     0.0000    0.0000    0.0000         1\n         362     0.0000    0.0000    0.0000         1\n         364     0.0000    0.0000    0.0000         1\n         366     0.0000    0.0000    0.0000         1\n         379     0.0000    0.0000    0.0000         1\n         394     0.0000    0.0000    0.0000         1\n         395     0.0000    0.0000    0.0000         1\n         400     0.0000    0.0000    0.0000         2\n         419     0.0000    0.0000    0.0000         5\n         422     0.0000    0.0000    0.0000         1\n         427     0.0000    0.0000    0.0000         1\n         428     0.0000    0.0000    0.0000         1\n         435     0.0000    0.0000    0.0000         1\n         439     0.0000    0.0000    0.0000         1\n         451     0.0000    0.0000    0.0000         1\n         453     0.0000    0.0000    0.0000         1\n         460     0.0000    0.0000    0.0000         1\n         467     0.0000    0.0000    0.0000         1\n         471     0.0000    0.0000    0.0000         1\n         477     0.0000    0.0000    0.0000         1\n         481     0.0000    0.0000    0.0000         1\n         497     0.0000    0.0000    0.0000         1\n         500     0.0000    0.0000    0.0000         1\n         511     0.0000    0.0000    0.0000         1\n         513     0.0000    0.0000    0.0000         1\n         530     0.0000    0.0000    0.0000         3\n         533     0.0000    0.0000    0.0000         1\n         542     0.0000    0.0000    0.0000         1\n         558     0.0000    0.0000    0.0000         1\n         559     0.0000    0.0000    0.0000         1\n         563     0.0000    0.0000    0.0000         1\n         568     0.0000    0.0000    0.0000         1\n         571     0.0000    0.0000    0.0000         1\n         572     0.0000    0.0000    0.0000         1\n         574     0.0000    0.0000    0.0000         2\n         579     0.0000    0.0000    0.0000         1\n         586     0.0000    0.0000    0.0000         1\n         589     0.0000    0.0000    0.0000         1\n         603     0.0000    0.0000    0.0000         1\n         604     0.0000    0.0000    0.0000         1\n         613     0.0000    0.0000    0.0000         1\n         620     0.0000    0.0000    0.0000         1\n         626     0.0000    0.0000    0.0000         1\n         627     0.0000    0.0000    0.0000         1\n         630     0.0000    0.0000    0.0000         1\n         640     0.0000    0.0000    0.0000         1\n         643     0.0000    0.0000    0.0000         1\n         646     0.0000    0.0000    0.0000         1\n         647     0.0000    0.0000    0.0000         1\n         662     0.0000    0.0000    0.0000         1\n         667     0.0000    0.0000    0.0000         4\n         676     0.0000    0.0000    0.0000         1\n         687     0.0000    0.0000    0.0000         1\n         689     0.0000    0.0000    0.0000         1\n         710     0.0000    0.0000    0.0000         1\n         713     0.0000    0.0000    0.0000         1\n         726     0.0000    0.0000    0.0000         1\n         743     0.0000    0.0000    0.0000         1\n         744     0.0000    0.0000    0.0000         1\n         745     0.0000    0.0000    0.0000         1\n         749     0.0000    0.0000    0.0000         1\n         756     0.0000    0.0000    0.0000         1\n         762     0.0000    0.0000    0.0000         1\n         763     0.0000    0.0000    0.0000         1\n         773     0.0000    0.0000    0.0000         1\n         774     0.0000    0.0000    0.0000         1\n         775     0.0000    0.0000    0.0000         1\n         777     0.0000    0.0000    0.0000         1\n         801     0.0000    0.0000    0.0000         1\n         808     0.0000    0.0000    0.0000         1\n         814     0.0000    0.0000    0.0000         1\n         821     0.0000    0.0000    0.0000         1\n         822     0.0000    0.0000    0.0000         1\n         829     0.0000    0.0000    0.0000         1\n         830     0.0000    0.0000    0.0000         6\n         842     0.0000    0.0000    0.0000         1\n         845     0.0000    0.0000    0.0000         1\n         852     0.0000    0.0000    0.0000         1\n         855     0.0000    0.0000    0.0000         1\n         857     0.0000    0.0000    0.0000         1\n         859     0.0000    0.0000    0.0000         1\n         867     0.0000    0.0000    0.0000         1\n         868     0.0000    0.0000    0.0000         1\n         891     0.0000    0.0000    0.0000         1\n         897     0.0000    0.0000    0.0000         2\n         903     0.0000    0.0000    0.0000         1\n         913     0.0000    0.0000    0.0000         1\n         922     0.0000    0.0000    0.0000         1\n         925     0.0000    0.0000    0.0000         1\n         928     0.0000    0.0000    0.0000         1\n         932     0.0000    0.0000    0.0000         1\n         940     0.0000    0.0000    0.0000         1\n         948     0.0000    0.0000    0.0000         1\n         954     0.0000    0.0000    0.0000         1\n         961     0.0000    0.0000    0.0000         1\n         968     0.0000    0.0000    0.0000         1\n         969     0.0000    0.0000    0.0000         1\n         974     0.0000    0.0000    0.0000         1\n         982     0.0000    0.0000    0.0000         1\n         989     0.0000    0.0000    0.0000         1\n        1000     0.0000    0.0000    0.0000         1\n        1002     0.0000    0.0000    0.0000         1\n        1003     0.0000    0.0000    0.0000         1\n        1009     0.0000    0.0000    0.0000         1\n        1017     0.0000    0.0000    0.0000         1\n        1029     0.0000    0.0000    0.0000         1\n        1037     0.0000    0.0000    0.0000         1\n        1040     0.0000    0.0000    0.0000         1\n        1043     0.0000    0.0000    0.0000         4\n        1058     0.0000    0.0000    0.0000         3\n        1067     0.0000    0.0000    0.0000         1\n        1070     0.0000    0.0000    0.0000         1\n        1076     0.0000    0.0000    0.0000         1\n        1079     0.0000    0.0000    0.0000         1\n        1084     0.0000    0.0000    0.0000         2\n        1087     0.0000    0.0000    0.0000         1\n        1100     0.0000    0.0000    0.0000         1\n        1107     0.0000    0.0000    0.0000         1\n        1114     0.0000    0.0000    0.0000         1\n        1117     0.0000    0.0000    0.0000         6\n        1119     0.0000    0.0000    0.0000         1\n        1127     0.0000    0.0000    0.0000         1\n        1128     0.0000    0.0000    0.0000         3\n        1137     0.0000    0.0000    0.0000         1\n        1140     0.0000    0.0000    0.0000         1\n        1150     0.0000    0.0000    0.0000         1\n        1156     0.0000    0.0000    0.0000         4\n        1163     0.0000    0.0000    0.0000         1\n        1190     0.0000    0.0000    0.0000         1\n        1193     0.0000    0.0000    0.0000         1\n        1195     0.0000    0.0000    0.0000         1\n        1196     0.0000    0.0000    0.0000         1\n        1201     0.0000    0.0000    0.0000         1\n        1205     0.0000    0.0000    0.0000         1\n        1206     0.0000    0.0000    0.0000         1\n        1209     0.0000    0.0000    0.0000         1\n        1212     0.0000    0.0000    0.0000         1\n        1213     0.0000    0.0000    0.0000         1\n        1214     0.0000    0.0000    0.0000         7\n        1218     0.0000    0.0000    0.0000         1\n        1229     0.0000    0.0000    0.0000         1\n        1240     0.0000    0.0000    0.0000         1\n        1241     0.0000    0.0000    0.0000         1\n        1248     0.0000    0.0000    0.0000         1\n        1252     0.0000    0.0000    0.0000         1\n        1264     0.0000    0.0000    0.0000         1\n        1269     0.0000    0.0000    0.0000         1\n        1271     0.0000    0.0000    0.0000         1\n        1281     0.0000    0.0000    0.0000         1\n        1304     0.0000    0.0000    0.0000         1\n        1313     0.0000    0.0000    0.0000         2\n        1323     0.0000    0.0000    0.0000         1\n        1340     0.0000    0.0000    0.0000         1\n        1349     0.0000    0.0000    0.0000         2\n        1354     0.0000    0.0000    0.0000         1\n        1364     0.0000    0.0000    0.0000         1\n        1374     0.0000    0.0000    0.0000         1\n        1382     0.0000    0.0000    0.0000         1\n        1385     0.0000    0.0000    0.0000         1\n        1387     0.0000    0.0000    0.0000         1\n        1389     0.0000    0.0000    0.0000         1\n        1394     0.0000    0.0000    0.0000         1\n        1395     0.0000    0.0000    0.0000         1\n        1401     0.0000    0.0000    0.0000         1\n        1413     0.0000    0.0000    0.0000         1\n        1416     0.0000    0.0000    0.0000         1\n        1428     0.0000    0.0000    0.0000         1\n        1435     0.0000    0.0000    0.0000         2\n        1441     0.0000    0.0000    0.0000         1\n        1442     0.0000    0.0000    0.0000        15\n        1444     0.0000    0.0000    0.0000         6\n        1467     0.0000    0.0000    0.0000         2\n        1486     0.0000    0.0000    0.0000         1\n        1489     0.0000    0.0000    0.0000         1\n        1493     0.0000    0.0000    0.0000         1\n        1504     0.0000    0.0000    0.0000         1\n        1506     0.0000    0.0000    0.0000         1\n        1511     0.0000    0.0000    0.0000         1\n        1524     0.0000    0.0000    0.0000         1\n        1533     0.0000    0.0000    0.0000         1\n        1541     0.0000    0.0000    0.0000         1\n        1542     0.0000    0.0000    0.0000         1\n        1550     0.0000    0.0000    0.0000         1\n        1557     0.0000    0.0000    0.0000         1\n        1558     0.0000    0.0000    0.0000         1\n        1564     0.0000    0.0000    0.0000         1\n        1572     0.0000    0.0000    0.0000         1\n        1575     0.0000    0.0000    0.0000         1\n        1583     0.0000    0.0000    0.0000         1\n        1592     0.0000    0.0000    0.0000         6\n        1596     0.0000    0.0000    0.0000         1\n        1599     0.0000    0.0000    0.0000         2\n        1604     0.0000    0.0000    0.0000         1\n        1607     0.0000    0.0000    0.0000         1\n        1627     0.0000    0.0000    0.0000         1\n        1638     0.0000    0.0000    0.0000         4\n        1640     0.0000    0.0000    0.0000         1\n        1643     0.0000    0.0000    0.0000         1\n        1645     0.0000    0.0000    0.0000         1\n        1657     0.0000    0.0000    0.0000         1\n        1660     0.0000    0.0000    0.0000         1\n        1666     0.0000    0.0000    0.0000         1\n        1674     0.0000    0.0000    0.0000         1\n        1676     0.0000    0.0000    0.0000         1\n        1685     0.0000    0.0000    0.0000         1\n        1695     0.0000    0.0000    0.0000         3\n        1696     0.0000    0.0000    0.0000         1\n        1698     0.0000    0.0000    0.0000         1\n        1701     0.0000    0.0000    0.0000         1\n        1725     0.0000    0.0000    0.0000         2\n        1733     0.0000    0.0000    0.0000         1\n        1734     0.0000    0.0000    0.0000         1\n        1736     0.0000    0.0000    0.0000         1\n        1740     0.0000    0.0000    0.0000         1\n        1747     0.0000    0.0000    0.0000         1\n        1750     0.0000    0.0000    0.0000         1\n        1752     0.0000    0.0000    0.0000         1\n        1757     0.0000    0.0000    0.0000         1\n        1758     0.0000    0.0000    0.0000         1\n        1762     0.0000    0.0000    0.0000         1\n        1773     0.0000    0.0000    0.0000         1\n        1783     0.0000    0.0000    0.0000         1\n        1794     0.0000    0.0000    0.0000         1\n        1797     0.0000    0.0000    0.0000         2\n        1802     0.0000    0.0000    0.0000         1\n        1809     0.0000    0.0000    0.0000         1\n        1812     0.0000    0.0000    0.0000         1\n        1823     0.0000    0.0000    0.0000         1\n        1834     0.0000    0.0000    0.0000         1\n        1845     0.0000    0.0000    0.0000         1\n        1850     0.0000    0.0000    0.0000         1\n        1881     0.0000    0.0000    0.0000         1\n        1883     0.0000    0.0000    0.0000         1\n        1894     0.0000    0.0000    0.0000         3\n        1902     0.0000    0.0000    0.0000         1\n        1907     0.0000    0.0000    0.0000         1\n        1910     0.0000    0.0000    0.0000         1\n        1917     0.0000    0.0000    0.0000         1\n        1921     0.0000    0.0000    0.0000         1\n        1923     0.0000    0.0000    0.0000         7\n        1930     0.0000    0.0000    0.0000         1\n        1931     0.0000    0.0000    0.0000         1\n        1939     0.0000    0.0000    0.0000         1\n        1947     0.0000    0.0000    0.0000         1\n        1968     0.0000    0.0000    0.0000         1\n        1975     0.0000    0.0000    0.0000         1\n        1978     0.0000    0.0000    0.0000         1\n        1982     0.0000    0.0000    0.0000         1\n        1996     0.0000    0.0000    0.0000         1\n        1999     0.0000    0.0000    0.0000         1\n        2000     0.0000    0.0000    0.0000         1\n        2001     0.0000    0.0000    0.0000         2\n        2006     0.0000    0.0000    0.0000         1\n        2013     0.0000    0.0000    0.0000         1\n        2017     0.0000    0.0000    0.0000         1\n        2026     0.0000    0.0000    0.0000         1\n        2030     0.0000    0.0000    0.0000         1\n        2038     0.0000    0.0000    0.0000         1\n        2047     0.0000    0.0000    0.0000         1\n        2050     0.0000    0.0000    0.0000         1\n        2059     0.0000    0.0000    0.0000         1\n        2086     0.0000    0.0000    0.0000         1\n        2092     0.0000    0.0000    0.0000         1\n        2096     0.0000    0.0000    0.0000         2\n        2099     0.0000    0.0000    0.0000        27\n        2101     0.0000    0.0000    0.0000         1\n        2102     0.0000    0.0000    0.0000         1\n        2103     0.0000    0.0000    0.0000        20\n        2105     0.0000    0.0000    0.0000         1\n        2112     0.0000    0.0000    0.0000         1\n        2115     0.0000    0.0000    0.0000         1\n        2118     0.0000    0.0000    0.0000         1\n        2124     0.0000    0.0000    0.0000         1\n        2126     0.0000    0.0000    0.0000         1\n        2148     0.0000    0.0000    0.0000         3\n        2158     0.0000    0.0000    0.0000         1\n        2159     0.0000    0.0000    0.0000         2\n        2160     0.0000    0.0000    0.0000         1\n        2165     0.0000    0.0000    0.0000         1\n        2166     0.0000    0.0000    0.0000         1\n        2169     0.0000    0.0000    0.0000         1\n        2170     0.0000    0.0000    0.0000         1\n        2180     0.0000    0.0000    0.0000         1\n        2186     0.0000    0.0000    0.0000         1\n        2190     0.0000    0.0000    0.0000         5\n        2191     0.0000    0.0000    0.0000         1\n        2194     0.0000    0.0000    0.0000         1\n        2211     0.0190    1.0000    0.0372        29\n        2213     0.0000    0.0000    0.0000         3\n        2214     0.0000    0.0000    0.0000         7\n        2218     0.0000    0.0000    0.0000         9\n        2219     0.0000    0.0000    0.0000        17\n        2221     0.0000    0.0000    0.0000         1\n        2229     0.0000    0.0000    0.0000         1\n        2233     0.0000    0.0000    0.0000         1\n        2234     0.0000    0.0000    0.0000         1\n        2235     0.0000    0.0000    0.0000         1\n        2247     0.0000    0.0000    0.0000         1\n        2261     0.0000    0.0000    0.0000         1\n        2262     0.0000    0.0000    0.0000         1\n        2263     0.0000    0.0000    0.0000         1\n        2264     0.0000    0.0000    0.0000         2\n        2271     0.0000    0.0000    0.0000         1\n        2276     0.0000    0.0000    0.0000         1\n        2281     0.0000    0.0000    0.0000         1\n        2286     0.0000    0.0000    0.0000         2\n        2292     0.0000    0.0000    0.0000         1\n        2303     0.0000    0.0000    0.0000         1\n        2305     0.0000    0.0000    0.0000         1\n        2310     0.0000    0.0000    0.0000         2\n        2314     0.0000    0.0000    0.0000         2\n        2316     0.0000    0.0000    0.0000         1\n        2327     0.0000    0.0000    0.0000         1\n        2343     0.0000    0.0000    0.0000         1\n        2347     0.0000    0.0000    0.0000         1\n        2349     0.0000    0.0000    0.0000         1\n        2351     0.0000    0.0000    0.0000         1\n        2352     0.0000    0.0000    0.0000         1\n        2353     0.0000    0.0000    0.0000         1\n        2379     0.0000    0.0000    0.0000         1\n        2388     0.0000    0.0000    0.0000         1\n        2396     0.0000    0.0000    0.0000         1\n        2397     0.0000    0.0000    0.0000         1\n        2398     0.0000    0.0000    0.0000         7\n        2402     0.0000    0.0000    0.0000         1\n        2410     0.0000    0.0000    0.0000         1\n        2412     0.0000    0.0000    0.0000         5\n        2427     0.0000    0.0000    0.0000         1\n        2432     0.0000    0.0000    0.0000         1\n        2434     0.0000    0.0000    0.0000         5\n        2452     0.0000    0.0000    0.0000         3\n        2456     0.0000    0.0000    0.0000         1\n        2462     0.0000    0.0000    0.0000         1\n        2473     0.0000    0.0000    0.0000         1\n        2474     0.0000    0.0000    0.0000         1\n        2476     0.0000    0.0000    0.0000         1\n        2501     0.0000    0.0000    0.0000        20\n        2507     0.0000    0.0000    0.0000         1\n        2510     0.0000    0.0000    0.0000         1\n        2511     0.0000    0.0000    0.0000         1\n        2512     0.0000    0.0000    0.0000         1\n        2513     0.0000    0.0000    0.0000         1\n        2517     0.0000    0.0000    0.0000         1\n        2519     0.0000    0.0000    0.0000         1\n        2532     0.0000    0.0000    0.0000         1\n        2536     0.0000    0.0000    0.0000         1\n        2537     0.0000    0.0000    0.0000         1\n        2538     0.0000    0.0000    0.0000         1\n        2539     0.0000    0.0000    0.0000         1\n        2551     0.0000    0.0000    0.0000         1\n        2552     0.0000    0.0000    0.0000         1\n        2559     0.0000    0.0000    0.0000         1\n        2563     0.0000    0.0000    0.0000         5\n        2569     0.0000    0.0000    0.0000         1\n        2570     0.0000    0.0000    0.0000         1\n        2577     0.0000    0.0000    0.0000         1\n        2578     0.0000    0.0000    0.0000         1\n        2583     0.0000    0.0000    0.0000         1\n        2587     0.0000    0.0000    0.0000         1\n        2601     0.0000    0.0000    0.0000         2\n        2606     0.0000    0.0000    0.0000         1\n        2608     0.0000    0.0000    0.0000         1\n        2610     0.0000    0.0000    0.0000         1\n        2611     0.0000    0.0000    0.0000         1\n        2626     0.0000    0.0000    0.0000         1\n        2628     0.0000    0.0000    0.0000         2\n        2634     0.0000    0.0000    0.0000         1\n        2640     0.0000    0.0000    0.0000         1\n        2661     0.0000    0.0000    0.0000        18\n        2662     0.0000    0.0000    0.0000         1\n        2663     0.0000    0.0000    0.0000         4\n        2677     0.0000    0.0000    0.0000         1\n        2679     0.0000    0.0000    0.0000         1\n        2683     0.0000    0.0000    0.0000         1\n        2686     0.0000    0.0000    0.0000         1\n        2692     0.0000    0.0000    0.0000         1\n        2699     0.0000    0.0000    0.0000         4\n        2712     0.0000    0.0000    0.0000         2\n        2717     0.0000    0.0000    0.0000         2\n        2733     0.0000    0.0000    0.0000         1\n        2753     0.0000    0.0000    0.0000         1\n        2766     0.0000    0.0000    0.0000         1\n        2771     0.0000    0.0000    0.0000         1\n        2776     0.0000    0.0000    0.0000         6\n        2778     0.0000    0.0000    0.0000         1\n        2787     0.0000    0.0000    0.0000         1\n        2790     0.0000    0.0000    0.0000         1\n        2797     0.0000    0.0000    0.0000         5\n        2804     0.0000    0.0000    0.0000         1\n        2805     0.0000    0.0000    0.0000         1\n        2806     0.0000    0.0000    0.0000         1\n        2807     0.0000    0.0000    0.0000         1\n        2827     0.0000    0.0000    0.0000         1\n        2842     0.0000    0.0000    0.0000         1\n        2849     0.0000    0.0000    0.0000         1\n        2878     0.0000    0.0000    0.0000         1\n        2891     0.0000    0.0000    0.0000         1\n        2892     0.0000    0.0000    0.0000         1\n        2903     0.0000    0.0000    0.0000         2\n        2904     0.0000    0.0000    0.0000         1\n        2907     0.0000    0.0000    0.0000         1\n        2915     0.0000    0.0000    0.0000         1\n        2918     0.0000    0.0000    0.0000         2\n        2947     0.0000    0.0000    0.0000         1\n        2955     0.0000    0.0000    0.0000         1\n        2961     0.0000    0.0000    0.0000         1\n        2963     0.0000    0.0000    0.0000         1\n        2967     0.0000    0.0000    0.0000         1\n        2975     0.0000    0.0000    0.0000         1\n        2979     0.0000    0.0000    0.0000         1\n        2994     0.0000    0.0000    0.0000         2\n        2995     0.0000    0.0000    0.0000         1\n        2996     0.0000    0.0000    0.0000         1\n        3011     0.0000    0.0000    0.0000         1\n        3015     0.0000    0.0000    0.0000         1\n        3024     0.0000    0.0000    0.0000         1\n        3030     0.0000    0.0000    0.0000         1\n        3045     0.0000    0.0000    0.0000         1\n        3065     0.0000    0.0000    0.0000         1\n        3067     0.0000    0.0000    0.0000         1\n        3069     0.0000    0.0000    0.0000         1\n        3070     0.0000    0.0000    0.0000         1\n        3078     0.0000    0.0000    0.0000         1\n        3081     0.0000    0.0000    0.0000         1\n        3084     0.0000    0.0000    0.0000         1\n        3087     0.0000    0.0000    0.0000         1\n        3095     0.0000    0.0000    0.0000         1\n        3108     0.0000    0.0000    0.0000         1\n        3112     0.0000    0.0000    0.0000         1\n        3115     0.0000    0.0000    0.0000         1\n        3116     0.0000    0.0000    0.0000         1\n        3118     0.0000    0.0000    0.0000         1\n        3122     0.0000    0.0000    0.0000         1\n        3129     0.0000    0.0000    0.0000         1\n        3138     0.0000    0.0000    0.0000         1\n        3156     0.0000    0.0000    0.0000         2\n        3161     0.0000    0.0000    0.0000         1\n        3162     0.0000    0.0000    0.0000         1\n        3164     0.0000    0.0000    0.0000         3\n        3165     0.0000    0.0000    0.0000         1\n        3172     0.0000    0.0000    0.0000         2\n        3178     0.0000    0.0000    0.0000         1\n        3188     0.0000    0.0000    0.0000         1\n        3193     0.0000    0.0000    0.0000         1\n        3196     0.0000    0.0000    0.0000         2\n        3198     0.0000    0.0000    0.0000         1\n        3221     0.0000    0.0000    0.0000         1\n        3225     0.0000    0.0000    0.0000         1\n        3226     0.0000    0.0000    0.0000         1\n        3228     0.0000    0.0000    0.0000         1\n        3244     0.0000    0.0000    0.0000         4\n        3246     0.0000    0.0000    0.0000         1\n        3253     0.0000    0.0000    0.0000         1\n        3259     0.0000    0.0000    0.0000         1\n        3261     0.0000    0.0000    0.0000         1\n        3263     0.0000    0.0000    0.0000         1\n        3269     0.0000    0.0000    0.0000         1\n        3285     0.0000    0.0000    0.0000         1\n        3289     0.0000    0.0000    0.0000         1\n        3291     0.0000    0.0000    0.0000         1\n        3295     0.0000    0.0000    0.0000         1\n        3306     0.0000    0.0000    0.0000         1\n        3307     0.0000    0.0000    0.0000         1\n        3319     0.0000    0.0000    0.0000         1\n        3320     0.0000    0.0000    0.0000         2\n        3321     0.0000    0.0000    0.0000         1\n        3324     0.0000    0.0000    0.0000         1\n        3330     0.0000    0.0000    0.0000         1\n        3335     0.0000    0.0000    0.0000         1\n        3337     0.0000    0.0000    0.0000         1\n        3338     0.0000    0.0000    0.0000         1\n        3339     0.0000    0.0000    0.0000         1\n        3348     0.0000    0.0000    0.0000         1\n        3359     0.0000    0.0000    0.0000         1\n        3360     0.0000    0.0000    0.0000         1\n        3362     0.0000    0.0000    0.0000         1\n        3363     0.0000    0.0000    0.0000         1\n        3365     0.0000    0.0000    0.0000         2\n        3370     0.0000    0.0000    0.0000         1\n        3374     0.0000    0.0000    0.0000         1\n        3377     0.0000    0.0000    0.0000         1\n        3380     0.0000    0.0000    0.0000         1\n        3385     0.0000    0.0000    0.0000         1\n        3387     0.0000    0.0000    0.0000         1\n        3388     0.0000    0.0000    0.0000         3\n        3391     0.0000    0.0000    0.0000         1\n        3393     0.0000    0.0000    0.0000         1\n        3394     0.0000    0.0000    0.0000         3\n        3401     0.0000    0.0000    0.0000         1\n        3403     0.0000    0.0000    0.0000         1\n        3406     0.0000    0.0000    0.0000         2\n        3410     0.0000    0.0000    0.0000         1\n        3412     0.0000    0.0000    0.0000         1\n        3415     0.0000    0.0000    0.0000         1\n        3417     0.0000    0.0000    0.0000         1\n        3425     0.0000    0.0000    0.0000         1\n        3439     0.0000    0.0000    0.0000         1\n        3443     0.0000    0.0000    0.0000         1\n        3444     0.0000    0.0000    0.0000         1\n        3445     0.0000    0.0000    0.0000         1\n        3450     0.0000    0.0000    0.0000         2\n        3461     0.0000    0.0000    0.0000         1\n        3468     0.0000    0.0000    0.0000         1\n        3473     0.0000    0.0000    0.0000         1\n        3477     0.0000    0.0000    0.0000         1\n        3480     0.0000    0.0000    0.0000         1\n        3482     0.0000    0.0000    0.0000         1\n        3484     0.0000    0.0000    0.0000         1\n        3486     0.0000    0.0000    0.0000         1\n        3489     0.0000    0.0000    0.0000         2\n        3497     0.0000    0.0000    0.0000         1\n        3504     0.0000    0.0000    0.0000         1\n        3509     0.0000    0.0000    0.0000         1\n        3535     0.0000    0.0000    0.0000         1\n        3546     0.0000    0.0000    0.0000         1\n        3552     0.0000    0.0000    0.0000         2\n        3559     0.0000    0.0000    0.0000         1\n        3564     0.0000    0.0000    0.0000         1\n        3566     0.0000    0.0000    0.0000         1\n        3568     0.0000    0.0000    0.0000         3\n        3574     0.0000    0.0000    0.0000         1\n        3583     0.0000    0.0000    0.0000         1\n        3603     0.0000    0.0000    0.0000         1\n        3606     0.0000    0.0000    0.0000         1\n        3625     0.0000    0.0000    0.0000         1\n        3638     0.0000    0.0000    0.0000         1\n        3646     0.0000    0.0000    0.0000         1\n        3650     0.0000    0.0000    0.0000         2\n        3665     0.0000    0.0000    0.0000         1\n        3668     0.0000    0.0000    0.0000         1\n        3674     0.0000    0.0000    0.0000         1\n        3680     0.0000    0.0000    0.0000         2\n        3686     0.0000    0.0000    0.0000         1\n        3689     0.0000    0.0000    0.0000         4\n        3700     0.0000    0.0000    0.0000         1\n        3703     0.0000    0.0000    0.0000         2\n        3706     0.0000    0.0000    0.0000         1\n        3709     0.0000    0.0000    0.0000         1\n        3710     0.0000    0.0000    0.0000         1\n        3716     0.0000    0.0000    0.0000         1\n        3728     0.0000    0.0000    0.0000         2\n        3730     0.0000    0.0000    0.0000         1\n        3738     0.0000    0.0000    0.0000         1\n        3739     0.0000    0.0000    0.0000         2\n        3759     0.0000    0.0000    0.0000         1\n        3770     0.0000    0.0000    0.0000         1\n        3773     0.0000    0.0000    0.0000         2\n        3776     0.0000    0.0000    0.0000         1\n        3777     0.0000    0.0000    0.0000         1\n        3782     0.0000    0.0000    0.0000         1\n        3783     0.0000    0.0000    0.0000         1\n        3786     0.0000    0.0000    0.0000         1\n        3796     0.0000    0.0000    0.0000         1\n        3805     0.0000    0.0000    0.0000         1\n        3807     0.0000    0.0000    0.0000         1\n        3817     0.0000    0.0000    0.0000         1\n        3820     0.0000    0.0000    0.0000         1\n        3825     0.0000    0.0000    0.0000         1\n        3840     0.0000    0.0000    0.0000         1\n        3844     0.0000    0.0000    0.0000         1\n        3845     0.0000    0.0000    0.0000         1\n        3853     0.0000    0.0000    0.0000         1\n        3862     0.0000    0.0000    0.0000         1\n        3873     0.0000    0.0000    0.0000         1\n        3878     0.0000    0.0000    0.0000         1\n        3887     0.0000    0.0000    0.0000         1\n        3893     0.0000    0.0000    0.0000         1\n        3898     0.0000    0.0000    0.0000         1\n        3903     0.0000    0.0000    0.0000         1\n        3905     0.0000    0.0000    0.0000         1\n        3908     0.0000    0.0000    0.0000         1\n        3913     0.0000    0.0000    0.0000         1\n        3948     0.0000    0.0000    0.0000         1\n        3953     0.0000    0.0000    0.0000         1\n        3955     0.0000    0.0000    0.0000         1\n        3956     0.0000    0.0000    0.0000         1\n        3958     0.0000    0.0000    0.0000         1\n        3983     0.0000    0.0000    0.0000         1\n        3992     0.0000    0.0000    0.0000         1\n        3996     0.0000    0.0000    0.0000         1\n        3998     0.0000    0.0000    0.0000         1\n        4000     0.0000    0.0000    0.0000         3\n        4002     0.0000    0.0000    0.0000         1\n        4003     0.0000    0.0000    0.0000         1\n        4005     0.0000    0.0000    0.0000         1\n        4023     0.0000    0.0000    0.0000         1\n        4025     0.0000    0.0000    0.0000         1\n        4031     0.0000    0.0000    0.0000         1\n        4033     0.0000    0.0000    0.0000         1\n        4036     0.0000    0.0000    0.0000         1\n        4039     0.0000    0.0000    0.0000         3\n        4050     0.0000    0.0000    0.0000         1\n        4065     0.0000    0.0000    0.0000         1\n        4079     0.0000    0.0000    0.0000         1\n        4087     0.0000    0.0000    0.0000         1\n        4101     0.0000    0.0000    0.0000         1\n        4111     0.0000    0.0000    0.0000         1\n        4128     0.0000    0.0000    0.0000         1\n        4132     0.0000    0.0000    0.0000         1\n        4158     0.0000    0.0000    0.0000         1\n        4178     0.0000    0.0000    0.0000         1\n        4179     0.0000    0.0000    0.0000         1\n        4193     0.0000    0.0000    0.0000         1\n        4199     0.0000    0.0000    0.0000         7\n        4202     0.0000    0.0000    0.0000         1\n        4205     0.0000    0.0000    0.0000         3\n        4210     0.0000    0.0000    0.0000         1\n        4216     0.0000    0.0000    0.0000         1\n        4218     0.0000    0.0000    0.0000         1\n        4233     0.0000    0.0000    0.0000         1\n        4235     0.0000    0.0000    0.0000         1\n        4245     0.0000    0.0000    0.0000         2\n        4250     0.0000    0.0000    0.0000         1\n        4251     0.0000    0.0000    0.0000         1\n        4255     0.0000    0.0000    0.0000         1\n        4267     0.0000    0.0000    0.0000         1\n        4270     0.0000    0.0000    0.0000         1\n        4271     0.0000    0.0000    0.0000         1\n        4276     0.0000    0.0000    0.0000         1\n        4277     0.0000    0.0000    0.0000         1\n        4285     0.0000    0.0000    0.0000         1\n        4286     0.0000    0.0000    0.0000         1\n        4288     0.0000    0.0000    0.0000         1\n        4299     0.0000    0.0000    0.0000         1\n        4317     0.0000    0.0000    0.0000         1\n        4318     0.0000    0.0000    0.0000         1\n        4323     0.0000    0.0000    0.0000         1\n        4340     0.0000    0.0000    0.0000         1\n        4343     0.0000    0.0000    0.0000         1\n        4358     0.0000    0.0000    0.0000         1\n        4363     0.0000    0.0000    0.0000         1\n        4372     0.0000    0.0000    0.0000         2\n        4382     0.0000    0.0000    0.0000         1\n        4383     0.0000    0.0000    0.0000         1\n        4389     0.0000    0.0000    0.0000         2\n        4394     0.0000    0.0000    0.0000         4\n        4396     0.0000    0.0000    0.0000         1\n        4404     0.0000    0.0000    0.0000         1\n        4409     0.0000    0.0000    0.0000         1\n        4416     0.0000    0.0000    0.0000         1\n        4432     0.0000    0.0000    0.0000         1\n        4434     0.0000    0.0000    0.0000         1\n        4441     0.0000    0.0000    0.0000         1\n        4444     0.0000    0.0000    0.0000         1\n        4456     0.0000    0.0000    0.0000         1\n        4468     0.0000    0.0000    0.0000         1\n        4471     0.0000    0.0000    0.0000         1\n        4475     0.0000    0.0000    0.0000         1\n        4480     0.0000    0.0000    0.0000         1\n        4491     0.0000    0.0000    0.0000         1\n        4494     0.0000    0.0000    0.0000         1\n        4514     0.0000    0.0000    0.0000         1\n        4519     0.0000    0.0000    0.0000         1\n        4520     0.0000    0.0000    0.0000         2\n        4521     0.0000    0.0000    0.0000         1\n        4525     0.0000    0.0000    0.0000         2\n        4528     0.0000    0.0000    0.0000         1\n        4532     0.0000    0.0000    0.0000        24\n        4538     0.0000    0.0000    0.0000         1\n        4539     0.0000    0.0000    0.0000         1\n        4540     0.0000    0.0000    0.0000         1\n        4542     0.0000    0.0000    0.0000         1\n        4543     0.0000    0.0000    0.0000         3\n        4545     0.0000    0.0000    0.0000         2\n        4558     0.0000    0.0000    0.0000         1\n        4559     0.0000    0.0000    0.0000         1\n        4560     0.0000    0.0000    0.0000         1\n        4575     0.0000    0.0000    0.0000         1\n        4581     0.0000    0.0000    0.0000         1\n        4586     0.0000    0.0000    0.0000         1\n        4588     0.0000    0.0000    0.0000         1\n        4591     0.0000    0.0000    0.0000         1\n        4598     0.0000    0.0000    0.0000         2\n        4601     0.0000    0.0000    0.0000         1\n        4628     0.0000    0.0000    0.0000         1\n        4631     0.0000    0.0000    0.0000         1\n        4634     0.0000    0.0000    0.0000         2\n        4640     0.0000    0.0000    0.0000         2\n        4641     0.0000    0.0000    0.0000         1\n        4642     0.0000    0.0000    0.0000         1\n        4649     0.0000    0.0000    0.0000         1\n        4652     0.0000    0.0000    0.0000         1\n        4655     0.0000    0.0000    0.0000         1\n        4656     0.0000    0.0000    0.0000         1\n        4658     0.0000    0.0000    0.0000         1\n        4661     0.0000    0.0000    0.0000         1\n        4662     0.0000    0.0000    0.0000         1\n        4663     0.0000    0.0000    0.0000         1\n        4668     0.0000    0.0000    0.0000         1\n        4669     0.0000    0.0000    0.0000         1\n        4675     0.0000    0.0000    0.0000         1\n        4684     0.0000    0.0000    0.0000         1\n        4685     0.0000    0.0000    0.0000         1\n        4688     0.0000    0.0000    0.0000         1\n        4691     0.0000    0.0000    0.0000         2\n        4693     0.0000    0.0000    0.0000         1\n        4697     0.0000    0.0000    0.0000         1\n        4698     0.0000    0.0000    0.0000         1\n        4700     0.0000    0.0000    0.0000         1\n        4714     0.0000    0.0000    0.0000         1\n        4724     0.0000    0.0000    0.0000         1\n        4729     0.0000    0.0000    0.0000         1\n        4730     0.0000    0.0000    0.0000         1\n        4735     0.0000    0.0000    0.0000         1\n        4742     0.0000    0.0000    0.0000         1\n        4743     0.0000    0.0000    0.0000         2\n        4747     0.0000    0.0000    0.0000         1\n        4751     0.0000    0.0000    0.0000         2\n        4752     0.0000    0.0000    0.0000         1\n        4753     0.0000    0.0000    0.0000         1\n        4756     0.0000    0.0000    0.0000         2\n        4760     0.0000    0.0000    0.0000         1\n        4767     0.0000    0.0000    0.0000         1\n        4770     0.0000    0.0000    0.0000         1\n        4771     0.0000    0.0000    0.0000         4\n        4777     0.0000    0.0000    0.0000        18\n        4782     0.0000    0.0000    0.0000         1\n        4785     0.0000    0.0000    0.0000         1\n        4793     0.0000    0.0000    0.0000         1\n        4798     0.0000    0.0000    0.0000         1\n        4803     0.0000    0.0000    0.0000         3\n        4814     0.0000    0.0000    0.0000         2\n        4817     0.0000    0.0000    0.0000         1\n        4822     0.0000    0.0000    0.0000         1\n        4823     0.0000    0.0000    0.0000         1\n        4828     0.0000    0.0000    0.0000         1\n        4834     0.0000    0.0000    0.0000         1\n        4854     0.0000    0.0000    0.0000         1\n        4859     0.0000    0.0000    0.0000         1\n        4868     0.0000    0.0000    0.0000         1\n        4873     0.0000    0.0000    0.0000         3\n        4886     0.0000    0.0000    0.0000         2\n        4891     0.0000    0.0000    0.0000         4\n        4902     0.0000    0.0000    0.0000         2\n        4909     0.0000    0.0000    0.0000         1\n        4911     0.0000    0.0000    0.0000         9\n        4912     0.0000    0.0000    0.0000         1\n        4914     0.0000    0.0000    0.0000         1\n        4921     0.0000    0.0000    0.0000         1\n        4926     0.0000    0.0000    0.0000         2\n        4927     0.0000    0.0000    0.0000         1\n        4932     0.0000    0.0000    0.0000         1\n        4933     0.0000    0.0000    0.0000         1\n        4939     0.0000    0.0000    0.0000         1\n        4946     0.0000    0.0000    0.0000         1\n        4954     0.0000    0.0000    0.0000         1\n        4958     0.0000    0.0000    0.0000         1\n        4959     0.0000    0.0000    0.0000         2\n        4962     0.0000    0.0000    0.0000         1\n        4966     0.0000    0.0000    0.0000         1\n        4983     0.0000    0.0000    0.0000         2\n        4986     0.0000    0.0000    0.0000         1\n        4992     0.0000    0.0000    0.0000         3\n        4995     0.0000    0.0000    0.0000         1\n        4996     0.0000    0.0000    0.0000         1\n        4997     0.0000    0.0000    0.0000         1\n        5008     0.0000    0.0000    0.0000         1\n        5009     0.0000    0.0000    0.0000         1\n        5010     0.0000    0.0000    0.0000         1\n        5018     0.0000    0.0000    0.0000         1\n        5019     0.0000    0.0000    0.0000         1\n        5021     0.0000    0.0000    0.0000         3\n        5022     0.0000    0.0000    0.0000         3\n        5025     0.0000    0.0000    0.0000         1\n        5026     0.0000    0.0000    0.0000         1\n        5031     0.0000    0.0000    0.0000         1\n        5034     0.0000    0.0000    0.0000         1\n        5036     0.0000    0.0000    0.0000         1\n        5041     0.0000    0.0000    0.0000         1\n        5050     0.0000    0.0000    0.0000         2\n        5059     0.0000    0.0000    0.0000         2\n        5062     0.0000    0.0000    0.0000         1\n        5068     0.0000    0.0000    0.0000         1\n        5069     0.0000    0.0000    0.0000         1\n        5072     0.0000    0.0000    0.0000         1\n        5073     0.0000    0.0000    0.0000         1\n        5075     0.0000    0.0000    0.0000        14\n        5076     0.0000    0.0000    0.0000         1\n        5080     0.0000    0.0000    0.0000         1\n        5089     0.0000    0.0000    0.0000         1\n        5101     0.0000    0.0000    0.0000         2\n        5106     0.0000    0.0000    0.0000         1\n        5108     0.0000    0.0000    0.0000         1\n        5118     0.0000    0.0000    0.0000         1\n        5119     0.0000    0.0000    0.0000         1\n        5123     0.0000    0.0000    0.0000         1\n        5124     0.0000    0.0000    0.0000         2\n        5132     0.0000    0.0000    0.0000         1\n        5133     0.0000    0.0000    0.0000         2\n        5141     0.0000    0.0000    0.0000         1\n        5142     0.0000    0.0000    0.0000         2\n        5143     0.0000    0.0000    0.0000         1\n        5155     0.0000    0.0000    0.0000         1\n        5167     0.0000    0.0000    0.0000         1\n        5171     0.0000    0.0000    0.0000         1\n        5173     0.0000    0.0000    0.0000         1\n        5194     0.0000    0.0000    0.0000         1\n        5201     0.0000    0.0000    0.0000         1\n        5221     0.0000    0.0000    0.0000         1\n        5223     0.0000    0.0000    0.0000         3\n        5226     0.0000    0.0000    0.0000         1\n        5230     0.0000    0.0000    0.0000         1\n        5243     0.0000    0.0000    0.0000         1\n        5245     0.0000    0.0000    0.0000         1\n        5251     0.0000    0.0000    0.0000         1\n        5262     0.0000    0.0000    0.0000         1\n        5267     0.0000    0.0000    0.0000         2\n        5268     0.0000    0.0000    0.0000         1\n        5272     0.0000    0.0000    0.0000         1\n        5273     0.0000    0.0000    0.0000         3\n        5274     0.0000    0.0000    0.0000         4\n        5275     0.0000    0.0000    0.0000         1\n        5280     0.0000    0.0000    0.0000         7\n        5282     0.0000    0.0000    0.0000         1\n        5292     0.0000    0.0000    0.0000         1\n        5293     0.0000    0.0000    0.0000         1\n        5294     0.0000    0.0000    0.0000         1\n        5296     0.0000    0.0000    0.0000         1\n        5308     0.0000    0.0000    0.0000         1\n        5311     0.0000    0.0000    0.0000         1\n        5312     0.0000    0.0000    0.0000         1\n        5313     0.0000    0.0000    0.0000         1\n        5323     0.0000    0.0000    0.0000         1\n        5325     0.0000    0.0000    0.0000         1\n        5332     0.0000    0.0000    0.0000         1\n        5333     0.0000    0.0000    0.0000         1\n        5341     0.0000    0.0000    0.0000         1\n        5345     0.0000    0.0000    0.0000         1\n        5351     0.0000    0.0000    0.0000         2\n        5355     0.0000    0.0000    0.0000         1\n        5362     0.0000    0.0000    0.0000         1\n        5374     0.0000    0.0000    0.0000         1\n        5379     0.0000    0.0000    0.0000         1\n        5381     0.0000    0.0000    0.0000         1\n        5383     0.0000    0.0000    0.0000         1\n        5397     0.0000    0.0000    0.0000         1\n        5402     0.0000    0.0000    0.0000         1\n        5403     0.0000    0.0000    0.0000         1\n        5409     0.0000    0.0000    0.0000         1\n        5414     0.0000    0.0000    0.0000         2\n        5418     0.0000    0.0000    0.0000         1\n        5422     0.0000    0.0000    0.0000         1\n        5423     0.0000    0.0000    0.0000         1\n        5425     0.0000    0.0000    0.0000        18\n        5432     0.0000    0.0000    0.0000         1\n        5434     0.0000    0.0000    0.0000         1\n        5443     0.0000    0.0000    0.0000         1\n        5462     0.0000    0.0000    0.0000         1\n        5464     0.0000    0.0000    0.0000         1\n        5465     0.0000    0.0000    0.0000         1\n        5469     0.0000    0.0000    0.0000         1\n        5474     0.0000    0.0000    0.0000         1\n        5487     0.0000    0.0000    0.0000         1\n        5488     0.0000    0.0000    0.0000         3\n        5489     0.0000    0.0000    0.0000         1\n        5507     0.0000    0.0000    0.0000         1\n        5514     0.0000    0.0000    0.0000         1\n        5516     0.0000    0.0000    0.0000         1\n        5520     0.0000    0.0000    0.0000         1\n        5526     0.0000    0.0000    0.0000         1\n        5527     0.0000    0.0000    0.0000         4\n        5540     0.0000    0.0000    0.0000         2\n        5548     0.0000    0.0000    0.0000         1\n        5569     0.0000    0.0000    0.0000         1\n        5572     0.0000    0.0000    0.0000         3\n        5588     0.0000    0.0000    0.0000         1\n        5591     0.0000    0.0000    0.0000         1\n        5598     0.0000    0.0000    0.0000         1\n        5606     0.0000    0.0000    0.0000         1\n        5610     0.0000    0.0000    0.0000         3\n        5612     0.0000    0.0000    0.0000         9\n        5620     0.0000    0.0000    0.0000         1\n        5622     0.0000    0.0000    0.0000         4\n        5625     0.0000    0.0000    0.0000         1\n        5628     0.0000    0.0000    0.0000         2\n        5633     0.0000    0.0000    0.0000         1\n        5636     0.0000    0.0000    0.0000         1\n        5637     0.0000    0.0000    0.0000         1\n        5639     0.0000    0.0000    0.0000         1\n        5640     0.0000    0.0000    0.0000        39\n        5642     0.0000    0.0000    0.0000         7\n        5659     0.0000    0.0000    0.0000         1\n        5661     0.0000    0.0000    0.0000        17\n        5663     0.0000    0.0000    0.0000         1\n        5665     0.0000    0.0000    0.0000         1\n        5666     0.0000    0.0000    0.0000         1\n        5672     0.0000    0.0000    0.0000        10\n        5674     0.0000    0.0000    0.0000         1\n        5680     0.0000    0.0000    0.0000         4\n        5686     0.0000    0.0000    0.0000         5\n        5687     0.0000    0.0000    0.0000         1\n        5689     0.0000    0.0000    0.0000         4\n        5692     0.0000    0.0000    0.0000         1\n        5694     0.0000    0.0000    0.0000         1\n\n    accuracy                         0.0190      1529\n   macro avg     0.0000    0.0011    0.0000      1529\nweighted avg     0.0004    0.0190    0.0007      1529\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"# entries = []\n# for identity, label, pred in zip(all_ids, all_labels_np, all_preds_np):\n#     entry = {\n#         'identity': identity,\n#         'label': all_labels[label],\n#         'pred': all_labels[pred]\n#     }\n#     entries.append(entry)\n\n# with open(f'/kaggle/working/{inf_model_name}_{CFG.lang}_val_preds.json', 'w') as fp:\n#     json.dump(entries, fp, cls=NpEncoder)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T09:33:58.134171Z","iopub.execute_input":"2024-06-05T09:33:58.134790Z","iopub.status.idle":"2024-06-05T09:33:58.157344Z","shell.execute_reply.started":"2024-06-05T09:33:58.134746Z","shell.execute_reply":"2024-06-05T09:33:58.156635Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# avg_test_loss, all_ids_test, all_preds_np_test, all_labels_np_test = validation_loop(inf_model, loss_fn, test_dataloader, 0)\n# if CFG.debug:\n#     print(all_labels_np_test)\n#     print(all_preds_np_test)\n    \n# score_test = get_score(all_labels_np_test, all_preds_np_test)\n\n# report_test = classification_report(all_labels_np_test, all_preds_np_test, digits=4)\n# print(report_test)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-05T09:34:00.074835Z","iopub.execute_input":"2024-06-05T09:34:00.075539Z","iopub.status.idle":"2024-06-05T09:35:36.767434Z","shell.execute_reply.started":"2024-06-05T09:34:00.075503Z","shell.execute_reply":"2024-06-05T09:35:36.766487Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/383 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e96db523a62145b386260402473da4a7"}},"metadata":{}},{"name":"stdout","text":"Epoch: [1][0/383] Elapsed 0m 0s (remain 1m 10s) Loss: 4.5519 (4.5519)\nEpoch: [1][50/383] Elapsed 0m 9s (remain 1m 4s) Loss: 5.7966 (5.1975)\nEpoch: [1][100/383] Elapsed 0m 21s (remain 1m 0s) Loss: 10.3884 (6.0287)\nEpoch: [1][150/383] Elapsed 0m 31s (remain 0m 48s) Loss: 8.3530 (6.9530)\nEpoch: [1][200/383] Elapsed 0m 44s (remain 0m 40s) Loss: 9.4853 (7.4494)\nEpoch: [1][250/383] Elapsed 0m 57s (remain 0m 30s) Loss: 9.6440 (7.8055)\nEpoch: [1][300/383] Elapsed 1m 14s (remain 0m 20s) Loss: 5.8731 (7.9028)\nEpoch: [1][350/383] Elapsed 1m 27s (remain 0m 7s) Loss: 7.4225 (7.7173)\nEpoch: [1][382/383] Elapsed 1m 36s (remain 0m 0s) Loss: 7.6207 (7.8045)\n[2211 5640 2189 ... 4198 4199 3208]\n[2211 2211 2211 ... 2211 2211 2211]\n              precision    recall  f1-score   support\n\n          14     0.0000    0.0000    0.0000         1\n          23     0.0000    0.0000    0.0000         1\n          32     0.0000    0.0000    0.0000         1\n          34     0.0000    0.0000    0.0000         1\n          38     0.0000    0.0000    0.0000         1\n          46     0.0000    0.0000    0.0000         2\n          48     0.0000    0.0000    0.0000         1\n          58     0.0000    0.0000    0.0000         1\n          87     0.0000    0.0000    0.0000         2\n          97     0.0000    0.0000    0.0000         1\n         104     0.0000    0.0000    0.0000         1\n         112     0.0000    0.0000    0.0000         2\n         113     0.0000    0.0000    0.0000         1\n         122     0.0000    0.0000    0.0000         1\n         129     0.0000    0.0000    0.0000         1\n         131     0.0000    0.0000    0.0000         1\n         134     0.0000    0.0000    0.0000         1\n         142     0.0000    0.0000    0.0000         2\n         158     0.0000    0.0000    0.0000         1\n         161     0.0000    0.0000    0.0000         1\n         162     0.0000    0.0000    0.0000         1\n         169     0.0000    0.0000    0.0000         1\n         185     0.0000    0.0000    0.0000         1\n         192     0.0000    0.0000    0.0000         1\n         193     0.0000    0.0000    0.0000         1\n         205     0.0000    0.0000    0.0000         1\n         213     0.0000    0.0000    0.0000         1\n         214     0.0000    0.0000    0.0000         1\n         218     0.0000    0.0000    0.0000         1\n         220     0.0000    0.0000    0.0000         1\n         226     0.0000    0.0000    0.0000         1\n         233     0.0000    0.0000    0.0000         1\n         236     0.0000    0.0000    0.0000         1\n         241     0.0000    0.0000    0.0000         1\n         242     0.0000    0.0000    0.0000         1\n         246     0.0000    0.0000    0.0000         1\n         258     0.0000    0.0000    0.0000         1\n         260     0.0000    0.0000    0.0000         1\n         277     0.0000    0.0000    0.0000         1\n         287     0.0000    0.0000    0.0000         1\n         300     0.0000    0.0000    0.0000         2\n         303     0.0000    0.0000    0.0000         1\n         306     0.0000    0.0000    0.0000         1\n         310     0.0000    0.0000    0.0000         1\n         318     0.0000    0.0000    0.0000         1\n         321     0.0000    0.0000    0.0000        20\n         323     0.0000    0.0000    0.0000         1\n         324     0.0000    0.0000    0.0000         1\n         325     0.0000    0.0000    0.0000         1\n         329     0.0000    0.0000    0.0000         1\n         337     0.0000    0.0000    0.0000         4\n         340     0.0000    0.0000    0.0000         1\n         363     0.0000    0.0000    0.0000         1\n         369     0.0000    0.0000    0.0000         1\n         390     0.0000    0.0000    0.0000         1\n         400     0.0000    0.0000    0.0000         1\n         401     0.0000    0.0000    0.0000         1\n         407     0.0000    0.0000    0.0000         1\n         417     0.0000    0.0000    0.0000         2\n         419     0.0000    0.0000    0.0000         1\n         437     0.0000    0.0000    0.0000         1\n         455     0.0000    0.0000    0.0000         1\n         458     0.0000    0.0000    0.0000         1\n         467     0.0000    0.0000    0.0000         1\n         471     0.0000    0.0000    0.0000         2\n         472     0.0000    0.0000    0.0000         1\n         475     0.0000    0.0000    0.0000         1\n         490     0.0000    0.0000    0.0000         1\n         493     0.0000    0.0000    0.0000         1\n         495     0.0000    0.0000    0.0000         1\n         503     0.0000    0.0000    0.0000         1\n         505     0.0000    0.0000    0.0000         1\n         511     0.0000    0.0000    0.0000         1\n         513     0.0000    0.0000    0.0000         1\n         530     0.0000    0.0000    0.0000         3\n         534     0.0000    0.0000    0.0000         1\n         535     0.0000    0.0000    0.0000         2\n         537     0.0000    0.0000    0.0000         1\n         541     0.0000    0.0000    0.0000         1\n         547     0.0000    0.0000    0.0000         1\n         550     0.0000    0.0000    0.0000         1\n         552     0.0000    0.0000    0.0000         1\n         561     0.0000    0.0000    0.0000         1\n         567     0.0000    0.0000    0.0000         1\n         569     0.0000    0.0000    0.0000         1\n         576     0.0000    0.0000    0.0000         1\n         578     0.0000    0.0000    0.0000         1\n         581     0.0000    0.0000    0.0000         1\n         584     0.0000    0.0000    0.0000         1\n         587     0.0000    0.0000    0.0000         1\n         594     0.0000    0.0000    0.0000         1\n         599     0.0000    0.0000    0.0000         1\n         602     0.0000    0.0000    0.0000         1\n         622     0.0000    0.0000    0.0000         1\n         627     0.0000    0.0000    0.0000         2\n         639     0.0000    0.0000    0.0000         1\n         653     0.0000    0.0000    0.0000         1\n         657     0.0000    0.0000    0.0000         1\n         663     0.0000    0.0000    0.0000         1\n         667     0.0000    0.0000    0.0000         9\n         669     0.0000    0.0000    0.0000         1\n         676     0.0000    0.0000    0.0000         1\n         677     0.0000    0.0000    0.0000         1\n         683     0.0000    0.0000    0.0000         1\n         687     0.0000    0.0000    0.0000         1\n         693     0.0000    0.0000    0.0000         1\n         696     0.0000    0.0000    0.0000         1\n         699     0.0000    0.0000    0.0000         1\n         700     0.0000    0.0000    0.0000         1\n         709     0.0000    0.0000    0.0000         1\n         713     0.0000    0.0000    0.0000         1\n         714     0.0000    0.0000    0.0000         1\n         717     0.0000    0.0000    0.0000         1\n         730     0.0000    0.0000    0.0000         1\n         732     0.0000    0.0000    0.0000         1\n         733     0.0000    0.0000    0.0000         1\n         777     0.0000    0.0000    0.0000         1\n         788     0.0000    0.0000    0.0000         2\n         792     0.0000    0.0000    0.0000         1\n         826     0.0000    0.0000    0.0000         1\n         828     0.0000    0.0000    0.0000         1\n         830     0.0000    0.0000    0.0000         1\n         831     0.0000    0.0000    0.0000         1\n         833     0.0000    0.0000    0.0000         1\n         842     0.0000    0.0000    0.0000         2\n         844     0.0000    0.0000    0.0000         1\n         845     0.0000    0.0000    0.0000         1\n         858     0.0000    0.0000    0.0000         1\n         861     0.0000    0.0000    0.0000         1\n         864     0.0000    0.0000    0.0000         1\n         865     0.0000    0.0000    0.0000         2\n         868     0.0000    0.0000    0.0000         1\n         886     0.0000    0.0000    0.0000         1\n         890     0.0000    0.0000    0.0000         1\n         906     0.0000    0.0000    0.0000         1\n         912     0.0000    0.0000    0.0000         1\n         913     0.0000    0.0000    0.0000         1\n         915     0.0000    0.0000    0.0000         1\n         924     0.0000    0.0000    0.0000         1\n         929     0.0000    0.0000    0.0000         1\n         944     0.0000    0.0000    0.0000         1\n         948     0.0000    0.0000    0.0000         3\n         954     0.0000    0.0000    0.0000         1\n         956     0.0000    0.0000    0.0000         1\n         959     0.0000    0.0000    0.0000         1\n         961     0.0000    0.0000    0.0000         1\n         963     0.0000    0.0000    0.0000         1\n         972     0.0000    0.0000    0.0000         1\n         974     0.0000    0.0000    0.0000         2\n         976     0.0000    0.0000    0.0000         1\n         982     0.0000    0.0000    0.0000         1\n        1003     0.0000    0.0000    0.0000         1\n        1010     0.0000    0.0000    0.0000         1\n        1015     0.0000    0.0000    0.0000         1\n        1020     0.0000    0.0000    0.0000         1\n        1029     0.0000    0.0000    0.0000         1\n        1039     0.0000    0.0000    0.0000         1\n        1043     0.0000    0.0000    0.0000         6\n        1045     0.0000    0.0000    0.0000         1\n        1048     0.0000    0.0000    0.0000         1\n        1049     0.0000    0.0000    0.0000         1\n        1051     0.0000    0.0000    0.0000         1\n        1052     0.0000    0.0000    0.0000         1\n        1058     0.0000    0.0000    0.0000         5\n        1064     0.0000    0.0000    0.0000         1\n        1071     0.0000    0.0000    0.0000         1\n        1077     0.0000    0.0000    0.0000         1\n        1079     0.0000    0.0000    0.0000         2\n        1084     0.0000    0.0000    0.0000         1\n        1087     0.0000    0.0000    0.0000         1\n        1089     0.0000    0.0000    0.0000         1\n        1091     0.0000    0.0000    0.0000         2\n        1099     0.0000    0.0000    0.0000         1\n        1112     0.0000    0.0000    0.0000         1\n        1117     0.0000    0.0000    0.0000         8\n        1120     0.0000    0.0000    0.0000         1\n        1126     0.0000    0.0000    0.0000         1\n        1132     0.0000    0.0000    0.0000         1\n        1140     0.0000    0.0000    0.0000         2\n        1145     0.0000    0.0000    0.0000         1\n        1147     0.0000    0.0000    0.0000         1\n        1156     0.0000    0.0000    0.0000         1\n        1157     0.0000    0.0000    0.0000         1\n        1161     0.0000    0.0000    0.0000         1\n        1166     0.0000    0.0000    0.0000         1\n        1171     0.0000    0.0000    0.0000         1\n        1177     0.0000    0.0000    0.0000         1\n        1185     0.0000    0.0000    0.0000         1\n        1191     0.0000    0.0000    0.0000         1\n        1195     0.0000    0.0000    0.0000         1\n        1203     0.0000    0.0000    0.0000         1\n        1206     0.0000    0.0000    0.0000         2\n        1208     0.0000    0.0000    0.0000         1\n        1210     0.0000    0.0000    0.0000         1\n        1214     0.0000    0.0000    0.0000         5\n        1220     0.0000    0.0000    0.0000         1\n        1228     0.0000    0.0000    0.0000         1\n        1240     0.0000    0.0000    0.0000         2\n        1243     0.0000    0.0000    0.0000         3\n        1244     0.0000    0.0000    0.0000         1\n        1245     0.0000    0.0000    0.0000         1\n        1248     0.0000    0.0000    0.0000         1\n        1256     0.0000    0.0000    0.0000         1\n        1259     0.0000    0.0000    0.0000         1\n        1260     0.0000    0.0000    0.0000         1\n        1280     0.0000    0.0000    0.0000         1\n        1282     0.0000    0.0000    0.0000         1\n        1283     0.0000    0.0000    0.0000         1\n        1302     0.0000    0.0000    0.0000         1\n        1313     0.0000    0.0000    0.0000         1\n        1316     0.0000    0.0000    0.0000         2\n        1322     0.0000    0.0000    0.0000         1\n        1324     0.0000    0.0000    0.0000         1\n        1325     0.0000    0.0000    0.0000         1\n        1328     0.0000    0.0000    0.0000         1\n        1336     0.0000    0.0000    0.0000         1\n        1340     0.0000    0.0000    0.0000         1\n        1341     0.0000    0.0000    0.0000         1\n        1344     0.0000    0.0000    0.0000         3\n        1345     0.0000    0.0000    0.0000         1\n        1354     0.0000    0.0000    0.0000         1\n        1355     0.0000    0.0000    0.0000         1\n        1357     0.0000    0.0000    0.0000         1\n        1364     0.0000    0.0000    0.0000         1\n        1369     0.0000    0.0000    0.0000         1\n        1382     0.0000    0.0000    0.0000         5\n        1385     0.0000    0.0000    0.0000         1\n        1390     0.0000    0.0000    0.0000         1\n        1393     0.0000    0.0000    0.0000         1\n        1396     0.0000    0.0000    0.0000         1\n        1400     0.0000    0.0000    0.0000         1\n        1404     0.0000    0.0000    0.0000         1\n        1417     0.0000    0.0000    0.0000         1\n        1424     0.0000    0.0000    0.0000         1\n        1435     0.0000    0.0000    0.0000         2\n        1437     0.0000    0.0000    0.0000         1\n        1442     0.0000    0.0000    0.0000        20\n        1444     0.0000    0.0000    0.0000         8\n        1451     0.0000    0.0000    0.0000         1\n        1466     0.0000    0.0000    0.0000         1\n        1476     0.0000    0.0000    0.0000         1\n        1482     0.0000    0.0000    0.0000         1\n        1500     0.0000    0.0000    0.0000         1\n        1517     0.0000    0.0000    0.0000         2\n        1521     0.0000    0.0000    0.0000         1\n        1526     0.0000    0.0000    0.0000         1\n        1545     0.0000    0.0000    0.0000         4\n        1555     0.0000    0.0000    0.0000         1\n        1559     0.0000    0.0000    0.0000         1\n        1564     0.0000    0.0000    0.0000         2\n        1565     0.0000    0.0000    0.0000         1\n        1568     0.0000    0.0000    0.0000         1\n        1583     0.0000    0.0000    0.0000         1\n        1590     0.0000    0.0000    0.0000         1\n        1592     0.0000    0.0000    0.0000         5\n        1593     0.0000    0.0000    0.0000         1\n        1599     0.0000    0.0000    0.0000         1\n        1605     0.0000    0.0000    0.0000         1\n        1608     0.0000    0.0000    0.0000         1\n        1609     0.0000    0.0000    0.0000         1\n        1617     0.0000    0.0000    0.0000         1\n        1626     0.0000    0.0000    0.0000         1\n        1632     0.0000    0.0000    0.0000         1\n        1635     0.0000    0.0000    0.0000         1\n        1637     0.0000    0.0000    0.0000         1\n        1638     0.0000    0.0000    0.0000         5\n        1639     0.0000    0.0000    0.0000         1\n        1645     0.0000    0.0000    0.0000         1\n        1656     0.0000    0.0000    0.0000         1\n        1676     0.0000    0.0000    0.0000         2\n        1700     0.0000    0.0000    0.0000         1\n        1702     0.0000    0.0000    0.0000         1\n        1713     0.0000    0.0000    0.0000         1\n        1714     0.0000    0.0000    0.0000         1\n        1716     0.0000    0.0000    0.0000         1\n        1717     0.0000    0.0000    0.0000         1\n        1721     0.0000    0.0000    0.0000         2\n        1734     0.0000    0.0000    0.0000         2\n        1744     0.0000    0.0000    0.0000         1\n        1747     0.0000    0.0000    0.0000         2\n        1754     0.0000    0.0000    0.0000         1\n        1755     0.0000    0.0000    0.0000         1\n        1785     0.0000    0.0000    0.0000         1\n        1795     0.0000    0.0000    0.0000         1\n        1797     0.0000    0.0000    0.0000         1\n        1815     0.0000    0.0000    0.0000         1\n        1823     0.0000    0.0000    0.0000         1\n        1825     0.0000    0.0000    0.0000         1\n        1839     0.0000    0.0000    0.0000         1\n        1840     0.0000    0.0000    0.0000         1\n        1845     0.0000    0.0000    0.0000         1\n        1847     0.0000    0.0000    0.0000         2\n        1860     0.0000    0.0000    0.0000         1\n        1890     0.0000    0.0000    0.0000         1\n        1893     0.0000    0.0000    0.0000         1\n        1898     0.0000    0.0000    0.0000         3\n        1899     0.0000    0.0000    0.0000         1\n        1906     0.0000    0.0000    0.0000         1\n        1923     0.0000    0.0000    0.0000         3\n        1950     0.0000    0.0000    0.0000         1\n        1953     0.0000    0.0000    0.0000         1\n        1956     0.0000    0.0000    0.0000         1\n        1963     0.0000    0.0000    0.0000         1\n        1970     0.0000    0.0000    0.0000         1\n        1972     0.0000    0.0000    0.0000         1\n        1973     0.0000    0.0000    0.0000         1\n        1997     0.0000    0.0000    0.0000         1\n        2001     0.0000    0.0000    0.0000         1\n        2002     0.0000    0.0000    0.0000         1\n        2009     0.0000    0.0000    0.0000         1\n        2016     0.0000    0.0000    0.0000         1\n        2017     0.0000    0.0000    0.0000         1\n        2021     0.0000    0.0000    0.0000         1\n        2031     0.0000    0.0000    0.0000         1\n        2037     0.0000    0.0000    0.0000         1\n        2041     0.0000    0.0000    0.0000         1\n        2048     0.0000    0.0000    0.0000         1\n        2052     0.0000    0.0000    0.0000         1\n        2057     0.0000    0.0000    0.0000         1\n        2083     0.0000    0.0000    0.0000         1\n        2092     0.0000    0.0000    0.0000         1\n        2095     0.0000    0.0000    0.0000         1\n        2099     0.0000    0.0000    0.0000        19\n        2103     0.0000    0.0000    0.0000        21\n        2143     0.0000    0.0000    0.0000         1\n        2144     0.0000    0.0000    0.0000         1\n        2147     0.0000    0.0000    0.0000         1\n        2148     0.0000    0.0000    0.0000         3\n        2150     0.0000    0.0000    0.0000         1\n        2158     0.0000    0.0000    0.0000         1\n        2159     0.0000    0.0000    0.0000         2\n        2160     0.0000    0.0000    0.0000         2\n        2164     0.0000    0.0000    0.0000         1\n        2166     0.0000    0.0000    0.0000         2\n        2188     0.0000    0.0000    0.0000         1\n        2189     0.0000    0.0000    0.0000         5\n        2190     0.0000    0.0000    0.0000         8\n        2194     0.0000    0.0000    0.0000         1\n        2204     0.0000    0.0000    0.0000         1\n        2205     0.0000    0.0000    0.0000         1\n        2206     0.0000    0.0000    0.0000         1\n        2211     0.0157    1.0000    0.0308        24\n        2213     0.0000    0.0000    0.0000         3\n        2214     0.0000    0.0000    0.0000        14\n        2218     0.0000    0.0000    0.0000         9\n        2219     0.0000    0.0000    0.0000        20\n        2242     0.0000    0.0000    0.0000         1\n        2244     0.0000    0.0000    0.0000         1\n        2245     0.0000    0.0000    0.0000         1\n        2259     0.0000    0.0000    0.0000         1\n        2261     0.0000    0.0000    0.0000         2\n        2265     0.0000    0.0000    0.0000         1\n        2266     0.0000    0.0000    0.0000         2\n        2270     0.0000    0.0000    0.0000         2\n        2281     0.0000    0.0000    0.0000         1\n        2284     0.0000    0.0000    0.0000         1\n        2287     0.0000    0.0000    0.0000         2\n        2290     0.0000    0.0000    0.0000         1\n        2292     0.0000    0.0000    0.0000         1\n        2294     0.0000    0.0000    0.0000         1\n        2301     0.0000    0.0000    0.0000         1\n        2302     0.0000    0.0000    0.0000         1\n        2308     0.0000    0.0000    0.0000         1\n        2310     0.0000    0.0000    0.0000         4\n        2315     0.0000    0.0000    0.0000         1\n        2316     0.0000    0.0000    0.0000         2\n        2333     0.0000    0.0000    0.0000         1\n        2343     0.0000    0.0000    0.0000         1\n        2344     0.0000    0.0000    0.0000         1\n        2345     0.0000    0.0000    0.0000         1\n        2348     0.0000    0.0000    0.0000         1\n        2352     0.0000    0.0000    0.0000         2\n        2368     0.0000    0.0000    0.0000         1\n        2380     0.0000    0.0000    0.0000         1\n        2383     0.0000    0.0000    0.0000         1\n        2384     0.0000    0.0000    0.0000         1\n        2398     0.0000    0.0000    0.0000         4\n        2399     0.0000    0.0000    0.0000         1\n        2402     0.0000    0.0000    0.0000         1\n        2412     0.0000    0.0000    0.0000         2\n        2416     0.0000    0.0000    0.0000         1\n        2420     0.0000    0.0000    0.0000         1\n        2430     0.0000    0.0000    0.0000         1\n        2433     0.0000    0.0000    0.0000         1\n        2434     0.0000    0.0000    0.0000         3\n        2438     0.0000    0.0000    0.0000         1\n        2452     0.0000    0.0000    0.0000         1\n        2456     0.0000    0.0000    0.0000         1\n        2457     0.0000    0.0000    0.0000         1\n        2461     0.0000    0.0000    0.0000         1\n        2463     0.0000    0.0000    0.0000         2\n        2473     0.0000    0.0000    0.0000         3\n        2474     0.0000    0.0000    0.0000         1\n        2478     0.0000    0.0000    0.0000         2\n        2482     0.0000    0.0000    0.0000         1\n        2488     0.0000    0.0000    0.0000         1\n        2500     0.0000    0.0000    0.0000         1\n        2501     0.0000    0.0000    0.0000        14\n        2502     0.0000    0.0000    0.0000         2\n        2511     0.0000    0.0000    0.0000         1\n        2516     0.0000    0.0000    0.0000         1\n        2522     0.0000    0.0000    0.0000         1\n        2527     0.0000    0.0000    0.0000         1\n        2531     0.0000    0.0000    0.0000         1\n        2546     0.0000    0.0000    0.0000         1\n        2549     0.0000    0.0000    0.0000         1\n        2557     0.0000    0.0000    0.0000         1\n        2563     0.0000    0.0000    0.0000         6\n        2565     0.0000    0.0000    0.0000         1\n        2567     0.0000    0.0000    0.0000         1\n        2568     0.0000    0.0000    0.0000         4\n        2580     0.0000    0.0000    0.0000         1\n        2582     0.0000    0.0000    0.0000         1\n        2584     0.0000    0.0000    0.0000         1\n        2588     0.0000    0.0000    0.0000         1\n        2601     0.0000    0.0000    0.0000         3\n        2606     0.0000    0.0000    0.0000         1\n        2608     0.0000    0.0000    0.0000         1\n        2617     0.0000    0.0000    0.0000         1\n        2618     0.0000    0.0000    0.0000         1\n        2628     0.0000    0.0000    0.0000         2\n        2629     0.0000    0.0000    0.0000         1\n        2641     0.0000    0.0000    0.0000         1\n        2644     0.0000    0.0000    0.0000         2\n        2648     0.0000    0.0000    0.0000         1\n        2651     0.0000    0.0000    0.0000         1\n        2656     0.0000    0.0000    0.0000         1\n        2659     0.0000    0.0000    0.0000         1\n        2661     0.0000    0.0000    0.0000        15\n        2663     0.0000    0.0000    0.0000         3\n        2667     0.0000    0.0000    0.0000         1\n        2668     0.0000    0.0000    0.0000         1\n        2674     0.0000    0.0000    0.0000         1\n        2686     0.0000    0.0000    0.0000         2\n        2699     0.0000    0.0000    0.0000         2\n        2705     0.0000    0.0000    0.0000         1\n        2707     0.0000    0.0000    0.0000         1\n        2712     0.0000    0.0000    0.0000         2\n        2714     0.0000    0.0000    0.0000         1\n        2717     0.0000    0.0000    0.0000         1\n        2721     0.0000    0.0000    0.0000         1\n        2728     0.0000    0.0000    0.0000         1\n        2731     0.0000    0.0000    0.0000         1\n        2732     0.0000    0.0000    0.0000         1\n        2734     0.0000    0.0000    0.0000         1\n        2737     0.0000    0.0000    0.0000         1\n        2751     0.0000    0.0000    0.0000         1\n        2753     0.0000    0.0000    0.0000         2\n        2754     0.0000    0.0000    0.0000         1\n        2760     0.0000    0.0000    0.0000         1\n        2763     0.0000    0.0000    0.0000         1\n        2776     0.0000    0.0000    0.0000         3\n        2784     0.0000    0.0000    0.0000         1\n        2792     0.0000    0.0000    0.0000         1\n        2797     0.0000    0.0000    0.0000         4\n        2805     0.0000    0.0000    0.0000         1\n        2814     0.0000    0.0000    0.0000         1\n        2825     0.0000    0.0000    0.0000         1\n        2829     0.0000    0.0000    0.0000         1\n        2838     0.0000    0.0000    0.0000         1\n        2841     0.0000    0.0000    0.0000         2\n        2842     0.0000    0.0000    0.0000         1\n        2850     0.0000    0.0000    0.0000         1\n        2857     0.0000    0.0000    0.0000         1\n        2861     0.0000    0.0000    0.0000         1\n        2866     0.0000    0.0000    0.0000         1\n        2879     0.0000    0.0000    0.0000         1\n        2895     0.0000    0.0000    0.0000         1\n        2897     0.0000    0.0000    0.0000         1\n        2898     0.0000    0.0000    0.0000         2\n        2901     0.0000    0.0000    0.0000         1\n        2903     0.0000    0.0000    0.0000         2\n        2904     0.0000    0.0000    0.0000         1\n        2909     0.0000    0.0000    0.0000         1\n        2911     0.0000    0.0000    0.0000         1\n        2914     0.0000    0.0000    0.0000         2\n        2920     0.0000    0.0000    0.0000         1\n        2925     0.0000    0.0000    0.0000         1\n        2926     0.0000    0.0000    0.0000         1\n        2932     0.0000    0.0000    0.0000         1\n        2936     0.0000    0.0000    0.0000         1\n        2939     0.0000    0.0000    0.0000         1\n        2955     0.0000    0.0000    0.0000         2\n        2965     0.0000    0.0000    0.0000         1\n        2971     0.0000    0.0000    0.0000         1\n        3006     0.0000    0.0000    0.0000         1\n        3033     0.0000    0.0000    0.0000         1\n        3044     0.0000    0.0000    0.0000         1\n        3048     0.0000    0.0000    0.0000         1\n        3077     0.0000    0.0000    0.0000         1\n        3079     0.0000    0.0000    0.0000         1\n        3083     0.0000    0.0000    0.0000         1\n        3092     0.0000    0.0000    0.0000         1\n        3116     0.0000    0.0000    0.0000         1\n        3121     0.0000    0.0000    0.0000         1\n        3149     0.0000    0.0000    0.0000         1\n        3150     0.0000    0.0000    0.0000         1\n        3154     0.0000    0.0000    0.0000         1\n        3156     0.0000    0.0000    0.0000         1\n        3158     0.0000    0.0000    0.0000         1\n        3172     0.0000    0.0000    0.0000         3\n        3187     0.0000    0.0000    0.0000         1\n        3191     0.0000    0.0000    0.0000         1\n        3202     0.0000    0.0000    0.0000         1\n        3203     0.0000    0.0000    0.0000         1\n        3205     0.0000    0.0000    0.0000         2\n        3208     0.0000    0.0000    0.0000         1\n        3210     0.0000    0.0000    0.0000         1\n        3216     0.0000    0.0000    0.0000         1\n        3232     0.0000    0.0000    0.0000         1\n        3237     0.0000    0.0000    0.0000         1\n        3244     0.0000    0.0000    0.0000         2\n        3252     0.0000    0.0000    0.0000         1\n        3256     0.0000    0.0000    0.0000         1\n        3262     0.0000    0.0000    0.0000         2\n        3264     0.0000    0.0000    0.0000         1\n        3267     0.0000    0.0000    0.0000         1\n        3273     0.0000    0.0000    0.0000         1\n        3278     0.0000    0.0000    0.0000         1\n        3281     0.0000    0.0000    0.0000         1\n        3297     0.0000    0.0000    0.0000         1\n        3298     0.0000    0.0000    0.0000         1\n        3299     0.0000    0.0000    0.0000         1\n        3307     0.0000    0.0000    0.0000         1\n        3308     0.0000    0.0000    0.0000         1\n        3318     0.0000    0.0000    0.0000         1\n        3320     0.0000    0.0000    0.0000         4\n        3321     0.0000    0.0000    0.0000         1\n        3324     0.0000    0.0000    0.0000         1\n        3326     0.0000    0.0000    0.0000         1\n        3340     0.0000    0.0000    0.0000         2\n        3341     0.0000    0.0000    0.0000         1\n        3344     0.0000    0.0000    0.0000         1\n        3345     0.0000    0.0000    0.0000         1\n        3359     0.0000    0.0000    0.0000         1\n        3360     0.0000    0.0000    0.0000         2\n        3364     0.0000    0.0000    0.0000         1\n        3365     0.0000    0.0000    0.0000         2\n        3368     0.0000    0.0000    0.0000         1\n        3369     0.0000    0.0000    0.0000         1\n        3372     0.0000    0.0000    0.0000         1\n        3373     0.0000    0.0000    0.0000         1\n        3374     0.0000    0.0000    0.0000         1\n        3376     0.0000    0.0000    0.0000         1\n        3388     0.0000    0.0000    0.0000         2\n        3389     0.0000    0.0000    0.0000         1\n        3394     0.0000    0.0000    0.0000         1\n        3397     0.0000    0.0000    0.0000         1\n        3405     0.0000    0.0000    0.0000         1\n        3411     0.0000    0.0000    0.0000         1\n        3414     0.0000    0.0000    0.0000         1\n        3421     0.0000    0.0000    0.0000         1\n        3422     0.0000    0.0000    0.0000         2\n        3428     0.0000    0.0000    0.0000         1\n        3444     0.0000    0.0000    0.0000         4\n        3451     0.0000    0.0000    0.0000         1\n        3458     0.0000    0.0000    0.0000         1\n        3459     0.0000    0.0000    0.0000         1\n        3461     0.0000    0.0000    0.0000         4\n        3466     0.0000    0.0000    0.0000         1\n        3468     0.0000    0.0000    0.0000         1\n        3473     0.0000    0.0000    0.0000         1\n        3475     0.0000    0.0000    0.0000         1\n        3481     0.0000    0.0000    0.0000         1\n        3489     0.0000    0.0000    0.0000         1\n        3504     0.0000    0.0000    0.0000         1\n        3505     0.0000    0.0000    0.0000         1\n        3536     0.0000    0.0000    0.0000         1\n        3539     0.0000    0.0000    0.0000         1\n        3544     0.0000    0.0000    0.0000         1\n        3546     0.0000    0.0000    0.0000         2\n        3552     0.0000    0.0000    0.0000         1\n        3553     0.0000    0.0000    0.0000         1\n        3557     0.0000    0.0000    0.0000         1\n        3560     0.0000    0.0000    0.0000         1\n        3575     0.0000    0.0000    0.0000         1\n        3580     0.0000    0.0000    0.0000         1\n        3591     0.0000    0.0000    0.0000         1\n        3624     0.0000    0.0000    0.0000         1\n        3628     0.0000    0.0000    0.0000         1\n        3634     0.0000    0.0000    0.0000         1\n        3652     0.0000    0.0000    0.0000         1\n        3662     0.0000    0.0000    0.0000         1\n        3663     0.0000    0.0000    0.0000         1\n        3677     0.0000    0.0000    0.0000         1\n        3679     0.0000    0.0000    0.0000         1\n        3682     0.0000    0.0000    0.0000         1\n        3689     0.0000    0.0000    0.0000         2\n        3701     0.0000    0.0000    0.0000         1\n        3703     0.0000    0.0000    0.0000         1\n        3710     0.0000    0.0000    0.0000         1\n        3717     0.0000    0.0000    0.0000         1\n        3721     0.0000    0.0000    0.0000         1\n        3723     0.0000    0.0000    0.0000         1\n        3725     0.0000    0.0000    0.0000         1\n        3728     0.0000    0.0000    0.0000         2\n        3739     0.0000    0.0000    0.0000         1\n        3742     0.0000    0.0000    0.0000         2\n        3747     0.0000    0.0000    0.0000         1\n        3749     0.0000    0.0000    0.0000         1\n        3753     0.0000    0.0000    0.0000         2\n        3759     0.0000    0.0000    0.0000         1\n        3786     0.0000    0.0000    0.0000         2\n        3787     0.0000    0.0000    0.0000         1\n        3789     0.0000    0.0000    0.0000         1\n        3792     0.0000    0.0000    0.0000         1\n        3809     0.0000    0.0000    0.0000         1\n        3825     0.0000    0.0000    0.0000         1\n        3829     0.0000    0.0000    0.0000         1\n        3864     0.0000    0.0000    0.0000         2\n        3873     0.0000    0.0000    0.0000         2\n        3876     0.0000    0.0000    0.0000         1\n        3882     0.0000    0.0000    0.0000         1\n        3897     0.0000    0.0000    0.0000         1\n        3903     0.0000    0.0000    0.0000         1\n        3905     0.0000    0.0000    0.0000         1\n        3921     0.0000    0.0000    0.0000         1\n        3925     0.0000    0.0000    0.0000         1\n        3927     0.0000    0.0000    0.0000         1\n        3933     0.0000    0.0000    0.0000         1\n        3936     0.0000    0.0000    0.0000         1\n        3946     0.0000    0.0000    0.0000         2\n        3953     0.0000    0.0000    0.0000         2\n        3955     0.0000    0.0000    0.0000         1\n        3966     0.0000    0.0000    0.0000         1\n        3968     0.0000    0.0000    0.0000         1\n        3974     0.0000    0.0000    0.0000         1\n        3979     0.0000    0.0000    0.0000         1\n        3980     0.0000    0.0000    0.0000         1\n        3990     0.0000    0.0000    0.0000         1\n        3994     0.0000    0.0000    0.0000         1\n        4002     0.0000    0.0000    0.0000         3\n        4003     0.0000    0.0000    0.0000         1\n        4011     0.0000    0.0000    0.0000         1\n        4012     0.0000    0.0000    0.0000         1\n        4013     0.0000    0.0000    0.0000         1\n        4015     0.0000    0.0000    0.0000         1\n        4035     0.0000    0.0000    0.0000         1\n        4038     0.0000    0.0000    0.0000         1\n        4039     0.0000    0.0000    0.0000         2\n        4043     0.0000    0.0000    0.0000         1\n        4048     0.0000    0.0000    0.0000         1\n        4053     0.0000    0.0000    0.0000         1\n        4056     0.0000    0.0000    0.0000         1\n        4060     0.0000    0.0000    0.0000         1\n        4065     0.0000    0.0000    0.0000         1\n        4071     0.0000    0.0000    0.0000         1\n        4073     0.0000    0.0000    0.0000         3\n        4078     0.0000    0.0000    0.0000         1\n        4082     0.0000    0.0000    0.0000         1\n        4084     0.0000    0.0000    0.0000         1\n        4089     0.0000    0.0000    0.0000         1\n        4101     0.0000    0.0000    0.0000         1\n        4111     0.0000    0.0000    0.0000         1\n        4120     0.0000    0.0000    0.0000         2\n        4122     0.0000    0.0000    0.0000         1\n        4134     0.0000    0.0000    0.0000         1\n        4136     0.0000    0.0000    0.0000         1\n        4141     0.0000    0.0000    0.0000         1\n        4149     0.0000    0.0000    0.0000         1\n        4152     0.0000    0.0000    0.0000         1\n        4160     0.0000    0.0000    0.0000         1\n        4163     0.0000    0.0000    0.0000         1\n        4168     0.0000    0.0000    0.0000         1\n        4172     0.0000    0.0000    0.0000         1\n        4175     0.0000    0.0000    0.0000         1\n        4181     0.0000    0.0000    0.0000         1\n        4195     0.0000    0.0000    0.0000         1\n        4198     0.0000    0.0000    0.0000         2\n        4199     0.0000    0.0000    0.0000         5\n        4200     0.0000    0.0000    0.0000         2\n        4201     0.0000    0.0000    0.0000         1\n        4205     0.0000    0.0000    0.0000         2\n        4217     0.0000    0.0000    0.0000         1\n        4247     0.0000    0.0000    0.0000         1\n        4263     0.0000    0.0000    0.0000         1\n        4265     0.0000    0.0000    0.0000         1\n        4273     0.0000    0.0000    0.0000         1\n        4278     0.0000    0.0000    0.0000         1\n        4283     0.0000    0.0000    0.0000         1\n        4297     0.0000    0.0000    0.0000         1\n        4301     0.0000    0.0000    0.0000         1\n        4302     0.0000    0.0000    0.0000         1\n        4315     0.0000    0.0000    0.0000         1\n        4320     0.0000    0.0000    0.0000         1\n        4327     0.0000    0.0000    0.0000         1\n        4329     0.0000    0.0000    0.0000         1\n        4338     0.0000    0.0000    0.0000         1\n        4351     0.0000    0.0000    0.0000         1\n        4352     0.0000    0.0000    0.0000         1\n        4358     0.0000    0.0000    0.0000         2\n        4359     0.0000    0.0000    0.0000         1\n        4363     0.0000    0.0000    0.0000         1\n        4364     0.0000    0.0000    0.0000         3\n        4368     0.0000    0.0000    0.0000         1\n        4380     0.0000    0.0000    0.0000         1\n        4382     0.0000    0.0000    0.0000         1\n        4387     0.0000    0.0000    0.0000         1\n        4389     0.0000    0.0000    0.0000         1\n        4394     0.0000    0.0000    0.0000         2\n        4396     0.0000    0.0000    0.0000         2\n        4403     0.0000    0.0000    0.0000         3\n        4407     0.0000    0.0000    0.0000         1\n        4413     0.0000    0.0000    0.0000         1\n        4417     0.0000    0.0000    0.0000         1\n        4418     0.0000    0.0000    0.0000         1\n        4440     0.0000    0.0000    0.0000         1\n        4441     0.0000    0.0000    0.0000         2\n        4463     0.0000    0.0000    0.0000         1\n        4464     0.0000    0.0000    0.0000         1\n        4467     0.0000    0.0000    0.0000         1\n        4483     0.0000    0.0000    0.0000         2\n        4499     0.0000    0.0000    0.0000         1\n        4501     0.0000    0.0000    0.0000         1\n        4503     0.0000    0.0000    0.0000         1\n        4512     0.0000    0.0000    0.0000         1\n        4516     0.0000    0.0000    0.0000         2\n        4520     0.0000    0.0000    0.0000         1\n        4525     0.0000    0.0000    0.0000         1\n        4532     0.0000    0.0000    0.0000        27\n        4539     0.0000    0.0000    0.0000         2\n        4543     0.0000    0.0000    0.0000         1\n        4548     0.0000    0.0000    0.0000         1\n        4560     0.0000    0.0000    0.0000         1\n        4562     0.0000    0.0000    0.0000         1\n        4565     0.0000    0.0000    0.0000         1\n        4570     0.0000    0.0000    0.0000         1\n        4596     0.0000    0.0000    0.0000         1\n        4597     0.0000    0.0000    0.0000         1\n        4611     0.0000    0.0000    0.0000         1\n        4620     0.0000    0.0000    0.0000         1\n        4622     0.0000    0.0000    0.0000         1\n        4625     0.0000    0.0000    0.0000         1\n        4635     0.0000    0.0000    0.0000         1\n        4640     0.0000    0.0000    0.0000         1\n        4643     0.0000    0.0000    0.0000         1\n        4644     0.0000    0.0000    0.0000         1\n        4655     0.0000    0.0000    0.0000         2\n        4662     0.0000    0.0000    0.0000         2\n        4677     0.0000    0.0000    0.0000         1\n        4689     0.0000    0.0000    0.0000         1\n        4696     0.0000    0.0000    0.0000         1\n        4710     0.0000    0.0000    0.0000         1\n        4715     0.0000    0.0000    0.0000         1\n        4729     0.0000    0.0000    0.0000         1\n        4730     0.0000    0.0000    0.0000         1\n        4743     0.0000    0.0000    0.0000         2\n        4748     0.0000    0.0000    0.0000         1\n        4751     0.0000    0.0000    0.0000         1\n        4754     0.0000    0.0000    0.0000         1\n        4756     0.0000    0.0000    0.0000         4\n        4758     0.0000    0.0000    0.0000         1\n        4761     0.0000    0.0000    0.0000         1\n        4763     0.0000    0.0000    0.0000         1\n        4766     0.0000    0.0000    0.0000         1\n        4767     0.0000    0.0000    0.0000         1\n        4771     0.0000    0.0000    0.0000         2\n        4777     0.0000    0.0000    0.0000        18\n        4790     0.0000    0.0000    0.0000         1\n        4801     0.0000    0.0000    0.0000         1\n        4810     0.0000    0.0000    0.0000         1\n        4814     0.0000    0.0000    0.0000         1\n        4816     0.0000    0.0000    0.0000         1\n        4819     0.0000    0.0000    0.0000         1\n        4828     0.0000    0.0000    0.0000         1\n        4829     0.0000    0.0000    0.0000         1\n        4834     0.0000    0.0000    0.0000         1\n        4849     0.0000    0.0000    0.0000         1\n        4855     0.0000    0.0000    0.0000         1\n        4866     0.0000    0.0000    0.0000         1\n        4870     0.0000    0.0000    0.0000         1\n        4872     0.0000    0.0000    0.0000         1\n        4873     0.0000    0.0000    0.0000         1\n        4874     0.0000    0.0000    0.0000         1\n        4887     0.0000    0.0000    0.0000         1\n        4891     0.0000    0.0000    0.0000         6\n        4893     0.0000    0.0000    0.0000         1\n        4895     0.0000    0.0000    0.0000         1\n        4897     0.0000    0.0000    0.0000         1\n        4902     0.0000    0.0000    0.0000         1\n        4911     0.0000    0.0000    0.0000        11\n        4917     0.0000    0.0000    0.0000         2\n        4920     0.0000    0.0000    0.0000         1\n        4924     0.0000    0.0000    0.0000         1\n        4932     0.0000    0.0000    0.0000         1\n        4937     0.0000    0.0000    0.0000         1\n        4943     0.0000    0.0000    0.0000         1\n        4947     0.0000    0.0000    0.0000         1\n        4951     0.0000    0.0000    0.0000         1\n        4952     0.0000    0.0000    0.0000         1\n        4958     0.0000    0.0000    0.0000         1\n        4962     0.0000    0.0000    0.0000         1\n        4970     0.0000    0.0000    0.0000         1\n        4982     0.0000    0.0000    0.0000         1\n        4988     0.0000    0.0000    0.0000         1\n        4992     0.0000    0.0000    0.0000         1\n        5008     0.0000    0.0000    0.0000         1\n        5011     0.0000    0.0000    0.0000         3\n        5020     0.0000    0.0000    0.0000         3\n        5021     0.0000    0.0000    0.0000         3\n        5022     0.0000    0.0000    0.0000         2\n        5029     0.0000    0.0000    0.0000         1\n        5035     0.0000    0.0000    0.0000         1\n        5037     0.0000    0.0000    0.0000         1\n        5039     0.0000    0.0000    0.0000         2\n        5040     0.0000    0.0000    0.0000         5\n        5041     0.0000    0.0000    0.0000         1\n        5046     0.0000    0.0000    0.0000         2\n        5047     0.0000    0.0000    0.0000         1\n        5069     0.0000    0.0000    0.0000         2\n        5071     0.0000    0.0000    0.0000         1\n        5072     0.0000    0.0000    0.0000         1\n        5075     0.0000    0.0000    0.0000        24\n        5077     0.0000    0.0000    0.0000         1\n        5081     0.0000    0.0000    0.0000         1\n        5083     0.0000    0.0000    0.0000         1\n        5096     0.0000    0.0000    0.0000         2\n        5104     0.0000    0.0000    0.0000         1\n        5106     0.0000    0.0000    0.0000         3\n        5119     0.0000    0.0000    0.0000         1\n        5120     0.0000    0.0000    0.0000         2\n        5129     0.0000    0.0000    0.0000         1\n        5133     0.0000    0.0000    0.0000         1\n        5142     0.0000    0.0000    0.0000         1\n        5147     0.0000    0.0000    0.0000         1\n        5149     0.0000    0.0000    0.0000         1\n        5154     0.0000    0.0000    0.0000         1\n        5167     0.0000    0.0000    0.0000         1\n        5175     0.0000    0.0000    0.0000         1\n        5179     0.0000    0.0000    0.0000         1\n        5181     0.0000    0.0000    0.0000         1\n        5183     0.0000    0.0000    0.0000         2\n        5188     0.0000    0.0000    0.0000         1\n        5190     0.0000    0.0000    0.0000         1\n        5191     0.0000    0.0000    0.0000         1\n        5195     0.0000    0.0000    0.0000         1\n        5200     0.0000    0.0000    0.0000         1\n        5209     0.0000    0.0000    0.0000         1\n        5210     0.0000    0.0000    0.0000         1\n        5217     0.0000    0.0000    0.0000         1\n        5218     0.0000    0.0000    0.0000         1\n        5219     0.0000    0.0000    0.0000         1\n        5222     0.0000    0.0000    0.0000         1\n        5223     0.0000    0.0000    0.0000         1\n        5238     0.0000    0.0000    0.0000         1\n        5267     0.0000    0.0000    0.0000         2\n        5273     0.0000    0.0000    0.0000         3\n        5274     0.0000    0.0000    0.0000         2\n        5275     0.0000    0.0000    0.0000         3\n        5280     0.0000    0.0000    0.0000         1\n        5285     0.0000    0.0000    0.0000         1\n        5310     0.0000    0.0000    0.0000         1\n        5332     0.0000    0.0000    0.0000         1\n        5338     0.0000    0.0000    0.0000         1\n        5341     0.0000    0.0000    0.0000         2\n        5342     0.0000    0.0000    0.0000         2\n        5344     0.0000    0.0000    0.0000         1\n        5345     0.0000    0.0000    0.0000         4\n        5349     0.0000    0.0000    0.0000         1\n        5351     0.0000    0.0000    0.0000         1\n        5354     0.0000    0.0000    0.0000         1\n        5364     0.0000    0.0000    0.0000         1\n        5368     0.0000    0.0000    0.0000         1\n        5375     0.0000    0.0000    0.0000         1\n        5378     0.0000    0.0000    0.0000         1\n        5389     0.0000    0.0000    0.0000         1\n        5394     0.0000    0.0000    0.0000         1\n        5395     0.0000    0.0000    0.0000         1\n        5400     0.0000    0.0000    0.0000         1\n        5401     0.0000    0.0000    0.0000         1\n        5404     0.0000    0.0000    0.0000         1\n        5408     0.0000    0.0000    0.0000         1\n        5416     0.0000    0.0000    0.0000         1\n        5418     0.0000    0.0000    0.0000         1\n        5419     0.0000    0.0000    0.0000         1\n        5425     0.0000    0.0000    0.0000        15\n        5426     0.0000    0.0000    0.0000         1\n        5430     0.0000    0.0000    0.0000         1\n        5433     0.0000    0.0000    0.0000         1\n        5442     0.0000    0.0000    0.0000         1\n        5445     0.0000    0.0000    0.0000         1\n        5447     0.0000    0.0000    0.0000         1\n        5464     0.0000    0.0000    0.0000         1\n        5465     0.0000    0.0000    0.0000         2\n        5482     0.0000    0.0000    0.0000         1\n        5500     0.0000    0.0000    0.0000         1\n        5509     0.0000    0.0000    0.0000         1\n        5515     0.0000    0.0000    0.0000         1\n        5518     0.0000    0.0000    0.0000         1\n        5522     0.0000    0.0000    0.0000         1\n        5527     0.0000    0.0000    0.0000         1\n        5529     0.0000    0.0000    0.0000         1\n        5545     0.0000    0.0000    0.0000         1\n        5548     0.0000    0.0000    0.0000         1\n        5554     0.0000    0.0000    0.0000         1\n        5555     0.0000    0.0000    0.0000         4\n        5560     0.0000    0.0000    0.0000         3\n        5562     0.0000    0.0000    0.0000         1\n        5569     0.0000    0.0000    0.0000         2\n        5574     0.0000    0.0000    0.0000         1\n        5578     0.0000    0.0000    0.0000         1\n        5580     0.0000    0.0000    0.0000         1\n        5581     0.0000    0.0000    0.0000         1\n        5585     0.0000    0.0000    0.0000         1\n        5590     0.0000    0.0000    0.0000         1\n        5595     0.0000    0.0000    0.0000         1\n        5599     0.0000    0.0000    0.0000         1\n        5601     0.0000    0.0000    0.0000         1\n        5612     0.0000    0.0000    0.0000         5\n        5614     0.0000    0.0000    0.0000         1\n        5622     0.0000    0.0000    0.0000         4\n        5624     0.0000    0.0000    0.0000         2\n        5628     0.0000    0.0000    0.0000         1\n        5634     0.0000    0.0000    0.0000         1\n        5640     0.0000    0.0000    0.0000        26\n        5642     0.0000    0.0000    0.0000         1\n        5650     0.0000    0.0000    0.0000         1\n        5658     0.0000    0.0000    0.0000         1\n        5661     0.0000    0.0000    0.0000        22\n        5663     0.0000    0.0000    0.0000         5\n        5672     0.0000    0.0000    0.0000        18\n        5674     0.0000    0.0000    0.0000         1\n        5680     0.0000    0.0000    0.0000         6\n        5681     0.0000    0.0000    0.0000         1\n        5686     0.0000    0.0000    0.0000         4\n        5687     0.0000    0.0000    0.0000         1\n        5688     0.0000    0.0000    0.0000         1\n        5694     0.0000    0.0000    0.0000         3\n        5696     0.0000    0.0000    0.0000         2\n\n    accuracy                         0.0157      1532\n   macro avg     0.0000    0.0011    0.0000      1532\nweighted avg     0.0002    0.0157    0.0005      1532\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"# entries_test = []\n# for identity, label, pred in zip(all_ids_test, all_labels_np_test, all_preds_np_test):\n#     entry = {\n#         'identity': identity,\n#         'label': all_labels[label],\n#         'pred': all_labels[pred]\n#     }\n#     entries_test.append(entry)\n\n# with open(f'/kaggle/working/{inf_model_name}_{CFG.lang}_test_preds.json', 'w') as fp:\n#     json.dump(entries_test, fp, cls=NpEncoder)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T09:36:35.390337Z","iopub.execute_input":"2024-06-05T09:36:35.390711Z","iopub.status.idle":"2024-06-05T09:36:35.414760Z","shell.execute_reply.started":"2024-06-05T09:36:35.390681Z","shell.execute_reply":"2024-06-05T09:36:35.413781Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}