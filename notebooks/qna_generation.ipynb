{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "import base64\n",
    "import requests\n",
    "import pandas as pd \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_validation_images = os.listdir(\"dataset/bornon\") #chitron/bnature\n",
    "len(list_validation_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_copy = list_validation_images[:100]\n",
    "len(files_to_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = \"dataset/Bornon\" \n",
    "destination_folder = \"dataset/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in files_to_copy:\n",
    "  source_path = os.path.join(source_folder, filename)\n",
    "  destination_path = os.path.join(destination_folder, filename)\n",
    "  \n",
    "  if os.path.isfile(source_path):\n",
    "      shutil.copy2(source_path, destination_path)\n",
    "    #   print(f\"Copied {filename} to {destination_folder}\")\n",
    "  else:\n",
    "      print(f\"File {filename} not found in source folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"dataset/bornon_train_token.txt\", delimiter=\"#0\\s+\", names=[\"image_name\", \"caption\"], header=None)\n",
    "df_test = pd.read_csv(\"dataset/bornon_test_token.txt\", delimiter=\"#0\\s+\", names=[\"image_name\", \"caption\"], header=None)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate(gdf):\n",
    "    captions = gdf['caption'].to_list()\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_train.groupby(\"image_name\").apply(consolidate, include_groups=False).reset_index().rename(columns={0: 'captions'})\n",
    "df2 = df_test.groupby(\"image_name\").apply(consolidate, include_groups=False).reset_index().rename(columns={0: 'captions'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sort_values(by='image_name', key=lambda x: pd.to_numeric(x.str.rstrip('.jpg'), errors='coerce'), inplace=True)\n",
    "df2.sort_values(by='image_name', key=lambda x: pd.to_numeric(x.str.rstrip('.jpg'), errors='coerce'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], axis=0)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"top_captioned.csv\")\n",
    "df = pd.read_csv(\"dataset/generated_bornon.csv\")\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = df['image_name'].isin(files_to_copy)\n",
    "# validation = df[mask]\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API = os.getenv(\"NEW_OPENAI_API\")\n",
    "GEMINI_API = os.getenv(\"GOOGLE_API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4 vision QnA and Captioning test for these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(captions):\n",
    "    return \"\"\"\n",
    "    You are an expert in generating Bengali visual question answers. For a given image and the captions to the image, your task is to generate the question and the answer. You should always abide by the guidelines that are mentioned below:\n",
    "\n",
    "    GUIDELINE 1:  The questions should be always image-aligned, caption-aligned, and informative \\\\\n",
    "    GUIDELINE 2:  Try to generate the answer in one or two words. The answer must never contain more than three words \\\\\n",
    "    GUIDELINE 3:  Generate the question-answer pair in the Bengali language \\\\\n",
    "    Here is the caption: \\\\\n",
    "    <CAPTION> {} \\\\\n",
    "    Based on the captions above and the image, generate one question-answer pair \n",
    "    in Bengali. Generate the question-answer pair in the following format:\\\\\n",
    "\n",
    "    Q\\# <GENERATED QUESTION>, A\\# <GENERATED ANSWER>\n",
    "    \"\"\".format(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_q_n_a(image_name, captions):\n",
    "    # Path to your image\n",
    "    image_path = f\"dataset/bornon/{image_name}\"\n",
    "\n",
    "    # Encode the image\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API}\"\n",
    "    }\n",
    "    payload = {\n",
    "        # \"model\": \"gpt-4-vision-preview\", \"gpt-4-turbo\"\n",
    "        \"model\": \"gpt-4-turbo\",\n",
    "        # \"response_format\": {\"type\": \"json_object\"},\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    # {\"type\": \"text\", \"text\": \"Caption the image explaining the contents in it. Use Bengali language to caption the image.\"},\n",
    "                    {\"type\": \"text\", \"text\": prompt(captions)},\n",
    "\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": \n",
    "    f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 100\n",
    "    }   \n",
    "\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    \n",
    "    return response.json()#['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[:,'Generated'] = None\n",
    "# df = final_df\n",
    "# df[400:415]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation.loc[:,'Generated'] = None\n",
    "# df.loc[:,'Generated'] = None\n",
    "# df = pd.read_csv(\"bornon-dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "sliced_df = df[0:1]\n",
    "# sliced_df.head(10)\n",
    "# validation.loc[validation['image_name'] == rows['image_name'], 'Generated'] = res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = 2397670 #1393072 # 325355\n",
    "total_input_tokens = 2176137 #405867 # 293207\n",
    "total_output_tokens = 482592 # 1537880 # 293207\n",
    "#  36.23913 # 3.8965100000000006 $\n",
    "val = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.read_csv(\"bornon-dataset.csv\")\n",
    "\n",
    "\n",
    "sliced_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, rows in sliced_df.iterrows():\n",
    "    res = (give_q_n_a(rows['image_name'], rows['top_captions']))\n",
    "    # print(prompt(rows['top_captions']))\n",
    "    total_input_tokens = total_input_tokens + res['usage']['prompt_tokens']\n",
    "    total_output_tokens = total_output_tokens + res['usage']['completion_tokens']\n",
    "    total_tokens = total_tokens + res['usage']['total_tokens']\n",
    "    df.loc[df['image_name'] == str(rows['image_name']), 'Generated'] = res['choices'][0]['message']['content']\n",
    "    print(\"done: \", val, \"input_token: \", res['usage']['prompt_tokens'], \"output_token: \", res['usage']['completion_tokens'])\n",
    "    val = val+1\n",
    "    time.sleep(1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total input tokens: \", total_input_tokens)\n",
    "print(\"total output tokens: \", total_output_tokens)\n",
    "print(\"total token count: \" , total_tokens)\n",
    "print(f\"total cost: {total_input_tokens * 1e-5 + total_output_tokens * 3e-5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total input tokens:  1393072\n",
    "total output tokens:  405867\n",
    "total token count:  1537880\n",
    "total cost: 26.10673"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation['Generated'] = validation['image_name'].apply(res)\n",
    "# res\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliced_df.tail()\n",
    "# merged_df = pd.merge(df, sliced_df, on=[\"image_name\", \"captions\", \"top_captions\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.rename(columns={\"Generated_y\": \"Generated\"}, inplace= True)\n",
    "# merged_df.drop('Generated_x',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Generated'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"dummy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset/generated_bornon.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_q_n_a(image_name, captions):\n",
    "    pass\n",
    "    # Path to your image\n",
    "    # image_path = f\"dataset/Bornon/{image_name}\"\n",
    "\n",
    "    # # Encode the image\n",
    "    # base64_image = encode_image(image_path)\n",
    "\n",
    "    # headers = {\n",
    "    #     \"Content-Type\": \"application/json\",\n",
    "    #     \"Authorization\": f\"Bearer {OPENAI_API}\"\n",
    "    # }\n",
    "    # payload = {\n",
    "    #     # \"model\": \"gpt-4-vision-preview\", \"gpt-4-turbo\"\n",
    "    #     \"model\": \"gpt-4-turbo\",\n",
    "    #     # \"response_format\": {\"type\": \"json_object\"},\n",
    "    #     \"messages\": [\n",
    "    #         {\n",
    "    #             \"role\": \"user\",\n",
    "    #             \"content\": [\n",
    "    #                 # {\"type\": \"text\", \"text\": \"Caption the image explaining the contents in it. Use Bengali language to caption the image.\"},\n",
    "    #                 {\"type\": \"text\", \"text\": f\"Generate a Question and answer pair in Bengali language based on the Captions: {captions} and the image given.\\\n",
    "    #                     give me the question and answer in the following format: \\\n",
    "    #                         Q#   'QUESTION_GENERATED', \\\n",
    "    #                         A#   'ANSWER_GENERATED',\\\n",
    "    #                     Please keep in mind that always generate the question keeping the context of the captions and the image. Also keep in mind that \\\n",
    "    #                         generate everything in Bengali. Generate only one question and answer pair. \\\n",
    "    #                     \"},\n",
    "\n",
    "    #                 {\"type\": \"image_url\", \"image_url\": {\"url\": \n",
    "    # f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "    #             ]\n",
    "    #         }\n",
    "    #     ],\n",
    "    #     \"max_tokens\": 300\n",
    "    # }   \n",
    "\n",
    "\n",
    "    # response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    \n",
    "    # return response.json()#['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import PIL.Image\n",
    "\n",
    "img = PIL.Image.open('dataset/Bornon/1.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=GEMINI_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.0-pro-vision-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_give_q_n_a(image, captions):\n",
    "    response = model.generate_content([f\"Generate a Question and answer pair in Bengali language based on the Captions: {captions} and the image given.\\\n",
    "                            give me the question and answer in the following format: \\\n",
    "                                Q: 'QUESTION_GENERATED',\\\n",
    "                                A: 'ANSWER_GENERATED',\\\n",
    "                            Please keep in mind that always generate the question keeping the context of the captions and the image. Also keep in mind that \\\n",
    "                                generate everything in Bengali \\\n",
    "                            \", image], stream=True)\n",
    "    response.resolve()\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_markdown(response.text)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_df = validation[95:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, rows in sliced_df.iterrows():\n",
    "    image_path = f\"dataset/validation/{rows['image_name']}\"\n",
    "    img = PIL.Image.open(image_path)\n",
    "    print((rows['image_name']), rows['captions'])\n",
    "    res = gemini_give_q_n_a(img , rows['captions'])\n",
    "    validation.loc[validation['image_name'] == str(rows['image_name']), 'Gemini_generated'] = res\n",
    "    # print(res)\n",
    "    time.sleep(3)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"dataset/Bornon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in images:\n",
    "    img = PIL.Image.open(f'{datapath}/{i}')\n",
    "    if img.__dict__['_size'] != (400, 400):\n",
    "        print(img.height, img.width)    \n",
    "        # print(img.__dict__['_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bornon Dataset\n",
    "each image size is 400*400. \n",
    "and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/generated_bornon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = df#[df['image_name'] == '237.jpg']\n",
    "# strs = dummy.iloc[0]['Generated']\n",
    "# strs = strs + \"Q# ছবিতে সময়টা কি কোনো বিশেষ পর্যায়ে আছে?\\nA# সূর্যাস্তের\"\n",
    "\n",
    "# strs.split('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_qa_string(qa_string):\n",
    "    parts = qa_string.split('A#')\n",
    "    \n",
    "    question = parts[0].replace('Q# ', '').strip().strip('\",')\n",
    "    answer = parts[1].strip().strip('\"')\n",
    "    \n",
    "    if len(parts) != 2:\n",
    "        print((parts))\n",
    "        question2 = parts[2].replace('Q# ', '').strip().strip('\",')\n",
    "        answer2 = parts[3].strip().strip('\"')\n",
    "        # print(question2, answer2)\n",
    "    return [question, answer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy['Generated_list'] = dummy['Generated'].apply(split_qa_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy[['Question', 'Answer']] = pd.DataFrame(dummy['Generated_list'].tolist(), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.drop(columns=['Generated_list'], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dummy.iloc[0]['top_captions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.drop(columns = 'captions', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(strs:str):\n",
    "    s = strs.split(',')\n",
    "    \n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.to_csv(\"dataset/generated_bornon.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uploadable to kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(\"dataset/bornon\")\n",
    "(images)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf = pd.read_csv(\"dataset/generated_bornon.csv\")\n",
    "\n",
    "udf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = udf[udf['image_name'].isin(images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset/bornon_subset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = set(df['Answer'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/unique_labels.txt', 'w') as file:\n",
    "    for label in uniques:\n",
    "        file.write(f\"{label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
